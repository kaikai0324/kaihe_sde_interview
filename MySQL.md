# MySQL

[toc]

## 1.索引：

innodb, myisam用B+tree
memory存储引擎用hash索引

ALTER TABLE people ADD INDEX fname_lname_age (firstname,lastname,age);

由于索引文件以B-树格式保存，MySQL能够立即转到合适的firstname，然后 再转到合适的lastname，最后转到合适的age。在没有扫描数据文件任何一个记录的情况下，MySQL就正确地找出了搜索的目标记录！

那么，如果在firstname、lastname、age这三个列上分别创建单列索引，效果是否和创建一个firstname、lastname、age 的多列索引一样呢？答案是否定的，两者完全不同。当我们执行查询的时候，MySQL只能使用一个索引。如果你有三个单列的索引，MySQL会试图选择一个限制最严格的索引。但是，即使是限制最严格的单列索引，它的限制能力也肯定远远低于firstname、lastname、age这三个列上的多列索引。

### 1.1最左前缀

多列索引还有另外一个 优点，它通过称为最左前缀（Leftmost Prefixing）的概念体现出来。继续考虑前面的例子，现在我们有一个firstname、lastname、age列上的多列索引，我们称这个索引 为fname_lname_age。当搜索条件是以下各种列的组合时，MySQL将使用fname_lname_age索引：

firstname，lastname，age

firstname，lastname

firstname
从另一方面理解，它相当于我们创建了(firstname，lastname，age)、(firstname，lastname)以及 (firstname)这些列组合上的索引。下面这些查询都能够使用这个fname_lname_age索引：

## 2.innodb行锁：

共享锁（S）：允许一个事务去读一行，阻止其他事务获得相同数据集的排他锁。LOCK IN SHARE MODE
排他锁（X）：允许获得排他锁的事务更新数据，阻止其他事务取得相同数据集的共享读锁和排他写锁。FOR UPDATE

共享锁又称读锁，是读取操作创建的锁。其他用户可以并发读取数据，但任何事务都不能对数据进行修改（获取数据上的排他锁），直到已释放所有共享锁。
排他锁又称写锁，如果事务T对数据A加上排他锁后，则其他事务不能再对A加任任何类型的封锁。获准排他锁的事务既能读数据，又能修改数据。





InnoDB的间隙锁：
当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。

很显然，在使用范围条件检索并锁定记录时，InnoDB这种加锁机制会阻塞符合条件范围内键值的并发插入，这往往会造成严重的锁等待。因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。

InnoDB使用间隙锁的目的：
防止幻读，以满足相关隔离级别的要求；
满足恢复和复制的需要：



## 3.mysql三大日志:

#### 3.1 binlog - 一致性

binlog 用于记录数据库执行的写入性操作(不包括查询)信息，以二进制的形式保存在磁盘中。binlog 是 mysql的逻辑日志，并且由 Server 层进行记录，使用任何存储引擎的 mysql 数据库都会记录 binlog 日志。

binlog记录了数据库表结构和表数据变更，存储着每条变更的SQL语句，不会记录select
主要有两个作用：复制和恢复数据
主从服务器需要保持数据的一致性，通过binlog来同步数据。
如果整个数据库的数据都被删除了，binlog存储着所有的数据变更情况，那么可以通过binlog来对数据进行恢复。

逻辑日志：可以简单理解为记录的就是sql语句 。
物理日志：mysql 数据最终是保存在数据页中的，物理日志记录的就是数据页变更 。
binlog 是通过追加的方式进行写入的，可以通过max_binlog_size 参数设置每个 binlog文件的大小，当文件大小达到给定值之后，会生成新的文件来保存日志。

binlog使用场景

在实际应用中， binlog 的主要使用场景有两个，分别是 主从复制 和 数据恢复 。

主从复制 ：在 Master 端开启 binlog ，然后将 binlog发送到各个 Slave 端， Slave 端重放 binlog 从而达到主从数据一致。
数据恢复 ：通过使用 mysqlbinlog 工具来恢复数据。



#### 3.2 redo log - 持久性

为什么需要redo log

我们都知道，事务的四大特性里面有一个是 持久性 ，具体来说就是只要事务提交成功，那么对数据库做的修改就被永久保存下来了，不可能因为任何原因再回到原来的状态 。

那么 mysql是如何保证一致性的呢？

最简单的做法是在每次事务提交的时候，将该事务涉及修改的数据页全部刷新到磁盘中。但是这么做会有严重的性能问题，主要体现在两个方面：

因为 Innodb 是以 页 为单位进行磁盘交互的，而一个事务很可能只修改一个数据页里面的几个字节，这个时候将完整的数据页刷到磁盘的话，太浪费资源了！
一个事务可能涉及修改多个数据页，并且这些数据页在物理上并不连续，使用随机IO写入性能太差！
因此 mysql 设计了 redo log ， 具体来说就是只记录事务对数据页做了哪些修改，这样就能完美地解决性能问题了(相对而言文件更小并且是顺序IO)。

redo log 包括两部分：一个是内存中的日志缓冲( redo log buffer )，另一个是磁盘上的日志文件( redo logfile)。
mysql 每执行一条 DML 语句，先将记录写入 redo log buffer，后续某个时间点再一次性将多个操作记录写到 redo log file。



#### 3.3 undo log - 原子性

数据库事务四大特性中有一个是 原子性 ，具体来说就是 原子性是指对数据库的一系列操作，要么全部成功，要么全部失败，不可能出现部分成功的情况。

实际上， 原子性 底层就是通过 undo log 实现的。undo log主要记录了数据的逻辑变化，比如一条 INSERT 语句，对应一条DELETE 的 undo log ，对于每个 UPDATE 语句，对应一条相反的 UPDATE 的 undo log ，这样在发生错误时，就能回滚到事务之前的数据状态。

同时， undo log 也是 MVCC(多版本并发控制)实现的关键



## 4. 事务的四大特性

#### 4.1 四大特性

![图片说明](https://uploadfiles.nowcoder.com/images/20210330/972694929_1617119642496/787AE2E621C6DA8A84B81E9CF1C40BAA)
**原子性** 

保持事务的原子性是指操作发生异常时，需要对该事务所有之前执行过的操作进行回滚。首先要设置autocommit=0，就是默认不能隐式提交，需要手动commit提交。回滚需要**undo日志**实现，undo日志存放之前修改过的记录，事务发生异常触发roll back，会按照日志逻辑回滚undo日志的操作。

**一致性**

一致性可以理解为事务对**数据完整性约束**的遵循。事务执行前后都是合法的数据状态，不会违背任何数据完整性

从数据库层面，数据库通过原子性、隔离性、持久性来保持一致性。

**隔离性**

用锁和隔离机制。锁是需要用户自己定义的，隔离机制是数据库提供的。

**持久性**

在无并发事务的情况下，持久性依赖于原子性；在有并发事务的情况下，持久性依赖于原子性和隔离性

即使数据库系统遇到故障也不会丢失已提交事务的操作，通过redo日志来实现的。基本步骤如下图 ：①当在事务中尝试对数据进行更改时；②首先将数据从磁盘读入内存，更新内存缓存的数据。③生成一条redo日志缓存，放在redo日志的缓冲区；④事务真正提交时将缓冲区中的日志写入redo日志做持久化保存；⑤把内存中的数据同步到磁盘上。

#### 4.2 **隔离级别**⭐⭐

在并发状态下，事务会出现一些问题，主要有三种问题：

**脏读** 一个事务能读到另外一个事务没有提交的数据。（举例：A给B转了100块，但是A转完并没有提交该事务，B读到了自己的账户多了100块，此时A发现转账错误之后就回滚了该操作，此时就称为脏读）

**不可重复读** 一个事务的两次查询操作数据不一致，可能是两次查询过程中插入了一个事务更新了原有的数据（举例：两个并发事务A和B，A首先查询自己的账户是100块，B此时提走了A账户的50块，A再次查询发现此时账户只剩下了50块，两次查询操作结果不同）

**幻读** 在一个事务的两次查询中数据不一致，发现了原来没有的数据或者原有的数据不见了

> 不可重复读与幻读相似，不可重复读侧重于另一个事务对数据库的`修改`操作，而幻读则侧重于另一个事务对数据库的`增加`和`删除`操作

###### Ⅰ.读未提交

允许读取另一个事务尚未提交的数据，可能会造成脏读、不可重复读、幻读

###### Ⅱ.读已提交

允许读取并发事务已经提交了的数据，可以阻止脏读，但是不能避免不可重复读和幻读

###### Ⅲ.可重复读

在一个事务的操作过程中，不能读取到别的事务对该数据库的修改增删操作，可以阻止脏读和不可重复读，但是不能避免幻读（mysql默认级别）

###### Ⅳ.串行化

所有的事务依次逐个执行，当表被一个事务操作时，其他事务的操作不可以进行，进入排队状态，等待当前操作事务提交后才能继续执行操作。

#### 4.3 锁

按使用方式分为**乐观锁**、**悲观锁**

按粒度分为表级锁、**行级锁**、页级锁 （InnoDB支持行级锁、表锁，MyISAM只支持表锁）

锁的粒度越小，系统开销越大，但相应的并发性就越高。因此选择锁粒度的时候需要在系统开销和并发性间权衡。

锁的类型上划分为**互斥锁/写锁/X锁、共享锁/读锁/S锁**

乐观锁一般为版本号（version)，在mvcc中有所体现



## 5. MySQL中的锁

### 5.1 表锁

- 表锁由 MySQL 服务器实现，所以无论你的存储引擎是什么，都可以使用。一般在执行 DDL 语句时，譬如 **ALTER TABLE** 就会对整个表进行加锁。在执行 SQL 语句时，也可以明确对某个表加锁，譬如下面的例子：

```sql
mysql> lock table products read;
Query OK, 0 rows affected (0.00 sec)
 
mysql> select * from products where id = 100;
 
mysql> unlock tables;
Query OK, 0 rows affected (0.00 sec)
```

- 上面的 SQL 首先对 products 表加一个表锁，然后执行查询语句，最后释放表锁。表锁可以细分成两种：读锁和写锁，如果是加写锁，则是 `lock table products write` 。

- 关于表锁，我们要了解它的加锁和解锁原则，要注意的是它使用的是 **一次封锁** 技术，也就是说，我们会在会话开始的地方使用 lock 命令将后面所有要用到的表加上锁，在锁释放之前，我们只能访问这些加锁的表，不能访问其他的表，最后通过 unlock tables 释放所有表锁。这样的好处是，不会发生死锁！所以我们在 MyISAM 存储引擎中，是不可能看到死锁场景的。对多个表加锁的例子如下：

  ```sql
  mysql> lock table products read, orders read;
  Query OK, 0 rows affected (0.00 sec)
   
  mysql> select * from products where id = 100;
   
  mysql> select * from orders where id = 200;
   
  mysql> select * from users where id = 300;
  ERROR 1100 (HY000): Table 'users' was not locked with LOCK TABLES
   
  mysql> update orders set price = 5000 where id = 200;
  ERROR 1099 (HY000): Table 'orders' was locked with a READ lock and can't be updated
   
  mysql> unlock tables;
  Query OK, 0 rows affected (0.00 sec)
  ```

  可以看到由于没有对 users 表加锁，在持有表锁的情况下是不能读取的，另外，由于加的是读锁，所以后面也不能对 orders 表进行更新。MySQL 表锁的加锁规则如下：

- 对于读锁

  - 持有读锁的会话可以读表，但不能写表；
  - 允许多个会话同时持有读锁；
  - 其他会话就算没有给表加读锁，也是可以读表的，但是不能写表；
  - 其他会话申请该表写锁时会阻塞，直到锁释放。

- 对于写锁

  - 持有写锁的会话既可以读表，也可以写表；
  - 只有持有写锁的会话才可以访问该表，其他会话访问该表会被阻塞，直到锁释放；
  - 其他会话无论申请该表的读锁或写锁，都会阻塞，直到锁释放。

- 锁的释放规则如下：

  - 使用 UNLOCK TABLES 语句可以显示释放表锁；
  - 如果会话在持有表锁的情况下执行 LOCK TABLES 语句，将会释放该会话之前持有的锁；
  - 如果会话在持有表锁的情况下执行 START TRANSACTION 或 BEGIN 开启一个事务，将会释放该会话之前持有的锁；
  - 如果会话连接断开，将会释放该会话所有的锁。

### 5.2 行锁

- 表锁不仅实现和使用都很简单，而且占用的系统资源少，所以在很多存储引擎中使用，如 MyISAM、MEMORY、MERGE 等，MyISAM 存储引擎几乎完全依赖 MySQL 服务器提供的表锁机制，查询自动加表级读锁，更新自动加表级写锁，以此来解决可能的并发问题。但是表锁的粒度太粗，导致数据库的并发性能降低，为了提高数据库的并发能力，InnoDb 引入了行锁的概念。行锁和表锁对比如下：

  - 表锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低；

  - 行锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高。

- 行锁和表锁一样，也分成两种类型：读锁和写锁。常见的增删改（INSERT、DELETE、UPDATE）语句会自动对操作的数据行加写锁，查询的时候也可以明确指定锁的类型，SELECT ... LOCK IN SHARE MODE 语句加的是读锁，SELECT ... FOR UPDATE 语句加的是写锁。

  - 共享锁/读锁（Shared Locks）：针对同一份数据，多个读操作可以同时进行，即读加锁，不能写并且可并行读 。

  ```sql
  select  math from zje where math>60 lock in share mode；
  ```

  - 排他锁/写锁（Exclusive Locks）：针对写操作，假如当前写操作没有完成，那么它会阻断其它的写锁和读锁，即写加锁，其它读写都阻塞 。

  ```sql
  select math from zje where math >60 for update；
  ```

- 行锁这个名字听起来像是这个锁加在某个数据行上，实际上这里要指出的是：在 MySQL 中，行锁是加在索引上的。

- 行锁种类

  - LOCK_ORDINARY：也称为 **Next-Key Lock**，锁一条记录及其之前的间隙，这是 RR 隔离级别用的最多的锁，从名字也能看出来；
  - LOCK_GAP：间隙锁，锁两个记录之间的 GAP，防止记录插入；
  - LOCK_REC_NOT_GAP：记录锁；
  - LOCK_INSERT_INTENSION：插入意向 GAP 锁，插入记录时使用，是 LOCK_GAP 的一种特例。

#### 5.2.1 记录锁（Record Locks）

- 记录锁是最简单的行锁。这条 SQL 语句就会在 id = 5 这条记录上加上记录锁，防止其他事务对 id = 5 这条记录进行修改或删除。譬如下面的 SQL 语句（id 为主键）：

```sql
mysql> UPDATE accounts SET level = 100 WHERE id = 5;
```

- 记录锁永远都是加在索引上的，就算一个表没有建索引，数据库也会隐式的创建一个索引。如果 WHERE 条件中指定的列是个二级索引，那么记录锁不仅会加在这个二级索引上，还会加在这个二级索引所对应的聚簇索引上。
- 注意，如果 SQL 语句无法使用索引时会走主索引实现全表扫描，这个时候 MySQL 会给整张表的所有数据行加记录锁。如果一个 WHERE 条件无法通过索引快速过滤，存储引擎层面就会将所有记录加锁后返回，再由 MySQL Server 层进行过滤。不过在实际使用过程中，MySQL 做了一些改进，在 MySQL Server 层进行过滤的时候，如果发现不满足，会调用 unlock_row 方法，把不满足条件的记录释放锁（显然这违背了二段锁协议）。这样做，保证了最后只会持有满足条件记录上的锁，但是每条记录的加锁操作还是不能省略的。可见在没有索引时，不仅会消耗大量的锁资源，增加数据库的开销，而且极大的降低了数据库的并发性能，所以说，更新操作一定要记得走索引。

#### 5.2.2 间隙锁（Gap Locks）

- 间隙锁是一种加在两个索引之间的锁，或者加在第一个索引之前，或最后一个索引之后的间隙。有时候又称为范围锁（Range Locks），这个范围可以跨一个索引记录，多个索引记录，甚至是空的。使用间隙锁可以防止其他事务在这个范围内插入或修改记录，保证两次读取这个范围内的记录不会变，从而不会出现幻读现象。
- 回到这个例子，这个 SQL 语句在 RC 隔离级别不会加任何锁，在 RR 隔离级别会在 id = 5 前后两个索引之间加上间隙锁。
- 值得注意的是，间隙锁和间隙锁之间是互不冲突的，间隙锁唯一的作用就是为了防止其他事务的插入，所以加间隙 S 锁和加间隙 X 锁没有任何区别。

#### 5.2.3 Next-Key Locks

- Next-Key Locks是记录锁和间隙锁的组合，它指的是加在某条记录以及这条记录前面间隙上的锁。
- 通常我们都用这种左开右闭区间来表示 Next-key 锁，其中，圆括号表示不包含该记录，方括号表示包含该记录。
- 在 RC 隔离级别下没有 Next-key 锁，只有 RR 隔离级别才有。
- 继续拿上面的 SQL 例子来说，如果 id 不是主键，而是二级索引，且不是唯一索引，那么这个 SQL 在 RR 隔离级别下会加Next-key 锁，如下：

  - (a, 5]
  - (5, b)
- 其中，a 和 b 是 id = 5 前后两个索引，我们假设 a = 1、b = 10，那么此时如果插入一条 id = 3 的记录将会阻塞住。之所以要把 id = 5 前后的间隙都锁住，仍然是为了解决幻读问题，因为 id 是非唯一索引，所以 id = 5 可能会有多条记录，为了防止再插入一条 id = 5 的记录，必须将下面标记 ^ 的位置都锁住，因为这些位置都可能再插入一条 id = 5 的记录：1 ^ 5 ^ 5 ^ 5 ^ 10 11 13 15
- 可以看出来，Next-key 锁确实可以避免幻读，但是带来的副作用是连插入 id = 3 这样的记录也被阻塞了，这根本就不会引起幻读问题的。

#### 5.2.4 插入意向锁（Insert Intention Locks）

- 插入意向锁是一种特殊的间隙锁（所以有的地方把它简写成 II GAP），这个锁表示插入的意向，只有在 INSERT 的时候才会有这个锁。注意，这个锁虽然也叫意向锁，但是和上面介绍的表级意向锁是两个完全不同的概念，不要搞混淆了。插入意向锁和插入意向锁之间互不冲突，所以可以在同一个间隙中有多个事务同时插入不同索引的记录。譬如在上面的例子中，id = 1 和 id = 5 之间如果有两个事务要同时分别插入 id = 2 和 id = 3 是没问题的，虽然两个事务都会在 id = 1 和 id = 5 之间加上插入意向锁，但是不会冲突。
- 插入意向锁只会和间隙锁或 Next-key 锁冲突，正如上面所说，间隙锁唯一的作用就是防止其他事务插入记录造成幻读，那么间隙锁是如何防止幻读的呢？正是由于在执行 INSERT 语句时需要加插入意向锁，而插入意向锁和间隙锁冲突，从而阻止了插入操作的执行。

#### 5.2.5 行锁的兼容矩阵

- 其中，**第一行表示已有的锁，第一列表示要加的锁**。

| 行锁的兼容矩阵   | Record | Gap  | Next-Key | Insert Intention |
| ---------------- | ------ | ---- | -------- | ---------------- |
| Record           |        | 兼容 |          | 兼容             |
| Gap              | 兼容   | 兼容 | 兼容     | 兼容             |
| Next-Key         |        | 兼容 |          | 兼容             |
| Insert Intention | 兼容   |      |          | 兼容             |

- 插入意向锁不影响其他事务加其他任何锁。也就是说，一个事务已经获取了插入意向锁，对其他事务是没有任何影响的；
- 插入意向锁与间隙锁和 Next-key 锁冲突。也就是说，一个事务想要获取插入意向锁，如果有其他事务已经加了间隙锁或 Next-key 锁，则会阻塞；
- 间隙锁不和其他锁（不包括插入意向锁）冲突；
- 记录锁和记录锁冲突，Next-key 锁和 Next-key 锁冲突，记录锁和 Next-key 锁冲突；

### 5.3 锁模式（lock_mode）

- 锁模式分为五种：
  - LOCK_IS：读意向锁；
  - LOCK_IX：写意向锁；
  - LOCK_S：读锁；
  - LOCK_X：写锁；
  - LOCK_AUTO_INC：自增锁；
- 将锁分为读锁和写锁主要是为了提高读的并发，如果不区分读写锁，那么数据库将没办法并发读，并发性将大大降低。而 IS（读意向）、IX（写意向）只会应用在表锁上，方便表锁和行锁之间的冲突检测。LOCK_AUTO_INC 是一种特殊的表锁。

#### 5.3.1 读写锁

- 读锁和写锁都是最基本的锁模式，它们的概念也比较容易理解。
- 读锁，又称共享锁（Share locks，简称 S 锁），加了读锁的记录，所有的事务都可以读取，但是不能修改，并且可同时有多个事务对记录加读锁。
- 写锁，又称排他锁（Exclusive locks，简称 X 锁），或独占锁，对记录加了排他锁之后，只有拥有该锁的事务可以读取和修改，其他事务都不可以读取和修改，并且同一时间只能有一个事务加写锁。（注意：这里说的读都是当前读，快照读是无需加锁的，记录上无论有没有锁，都可以快照读）

#### 5.3.2 读写意向锁

- 表锁锁定了整张表，而行锁是锁定表中的某条记录，它们俩锁定的范围有交集，因此表锁和行锁之间是有冲突的。譬如某个表有 10000 条记录，其中有一条记录加了 X 锁，如果这个时候系统需要对该表加表锁，为了判断是否能加这个表锁，系统需要遍历表中的所有 10000 条记录，看看是不是某条记录被加锁，如果有锁，则不允许加表锁，显然这是很低效的一种方法，为了方便检测表锁和行锁的冲突，从而引入了意向锁。
- 意向锁为表级锁，也可分为读意向锁（IS 锁）和写意向锁（IX 锁）。当事务试图读或写某一条记录时，会先在表上加上意向锁，然后才在要操作的记录上加上读锁或写锁。这样判断表中是否有记录加锁就很简单了，只要看下表上是否有意向锁就行了。意向锁之间是不会产生冲突的，也不和 AUTO_INC 表锁冲突，它只会阻塞表级读锁或表级写锁，另外，意向锁也不会和行锁冲突，行锁只会和行锁冲突。

#### 5.3.3 AUTO_INC 锁

- AUTO_INC 锁又叫自增锁（一般简写成 AI 锁），它是一种特殊类型的表锁，当插入的表中有自增列（AUTO_INCREMENT）的时候可能会遇到。当插入表中有自增列时，数据库需要自动生成自增值，在生成之前，它会先为该表加 AUTO_INC 表锁，其他事务的插入操作阻塞，这样保证生成的自增值肯定是唯一的。AUTO_INC 锁具有如下特点：
  - AUTO_INC 锁互不兼容，也就是说同一张表同时只允许有一个自增锁；
  - 自增锁不遵循二段锁协议，它并不是事务结束时释放，而是在 INSERT 语句执行结束时释放，这样可以提高并发插入的性能。
  - 自增值一旦分配了就会 +1，如果事务回滚，自增值也不会减回去，所以自增值可能会出现中断的情况。
- 显然，AUTO_INC 表锁会导致并发插入的效率降低，为了提高插入的并发性，MySQL 从 5.1.22 版本开始，引入了一种可选的轻量级锁（mutex）机制来代替 AUTO_INC 锁，我们可以通过参数 `innodb_autoinc_lock_mode` 控制分配自增值时的并发策略。参数 `innodb_autoinc_lock_mode` 可以取下列值：
  - innodb_autoinc_lock_mode = 0 （traditional lock mode）
    - 使用传统的 AUTO_INC 表锁，并发性比较差。
  - innodb_autoinc_lock_mode = 1 （consecutive lock mode）
    - MySQL 默认采用这种方式，是一种比较折中的方法。
    - MySQL 将插入语句分成三类：`Simple inserts、Bulk inserts、Mixed-mode inserts`。通过分析 INSERT 语句可以明确知道插入数量的叫做 `Simple inserts`，譬如最经常使用的 INSERT INTO table VALUE(1,2) 或 INSERT INTO table VALUES(1,2), (3,4)；通过分析 INSERT 语句无法确定插入数量的叫做 `Bulk inserts`，譬如 INSERT INTO table SELECT 或 LOAD DATA 等；还有一种是不确定是否需要分配自增值的，譬如 INSERT INTO table VALUES(1,'a'), (NULL,'b'), (5, 'C'), (NULL, 'd') 或 INSERT ... ON DUPLICATE KEY UPDATE，这种叫做 `Mixed-mode inserts`。
    - Bulk inserts 不能确定插入数使用表锁；Simple inserts 和 Mixed-mode inserts 使用轻量级锁 mutex，只锁住预分配自增值的过程，不锁整张表。Mixed-mode inserts 会直接分析语句，获得最坏情况下需要插入的数量，一次性分配足够的自增值，缺点是会分配过多，导致浪费和空洞。
    - 这种模式的好处是既平衡了并发性，又能保证同一条 INSERT 语句分配的自增值是连续的。
  - innodb_autoinc_lock_mode = 2 （interleaved lock mode）
    - 全部都用轻量级锁 mutex，并发性能最高，按顺序依次分配自增值，不会预分配。
    - 缺点是不能保证同一条 INSERT 语句内的自增值是连续的，这样在复制（replication）时，如果 binlog_format 为 statement-based（基于语句的复制）就会存在问题，因为是来一个分配一个，同一条 INSERT 语句内获得的自增值可能不连续，主从数据集会出现数据不一致。所以在做数据库同步时要特别注意这个配置。

#### 5.3.4 表锁的兼容矩阵

|      | IS   | IX   | S    | X    | AI   |
| ---- | ---- | ---- | ---- | ---- | ---- |
| IS   | 兼容 | 兼容 | 兼容 |      | 兼容 |
| IX   | 兼容 | 兼容 |      |      | 兼容 |
| S    | 兼容 |      | 兼容 |      |      |
| X    |      |      |      |      |      |
| AI   | 兼容 | 兼容 |      |      |      |

- 用一条斜线把表格分割成两个部分，只需要看左下角的一半即可。总结起来有下面几点：
  - 意向锁之间互不冲突；
  - S 锁只和 S/IS 锁兼容，和其他锁都冲突；
  - X 锁和其他所有锁都冲突；
  - AI 锁只和意向锁兼容；

### 5.4 悲观锁和乐观锁

- 悲观锁：

  - 先获取锁，再进行业务操作。
  - 通常来讲在数据库上的悲观锁需要数据库本身提供支持，即通过常用的select … for update操作来实现悲观锁。当数据库执行select for update时会获取被select中的数据行的行锁，因此其他并发执行的select for update如果试图选中同一行则会发生排斥（需要等待行锁被释放），因此达到锁的效果。select for update获取的行锁会在当前事务结束时自动释放，因此必须在事务中使用。
  - MySQL还有个问题是select for update语句执行中所有扫描过的行都会被锁上，这一点很容易造成问题。因此如果在MySQL中用悲观锁务必要确定走了索引，而不是全表扫描。

- 乐观锁：

  - 也叫乐观并发控制，它假设多用户并发的事务在处理时不会彼此互相影响，各事务能够在不产生锁的情况下处理各自影响的那部分数据。在提交数据更新之前，每个事务会先检查在该事务读取数据后，有没有其他事务又修改了该数据。如果其他事务有更新的话，那么当前正在提交的事务会进行回滚。

  - 乐观锁在数据库上的实现完全是逻辑的，不需要数据库提供特殊的支持。

  - 一般的做法是**在需要锁的数据上增加一个版本号，或者时间戳**，

    **实现方式举例如下：**

    **乐观锁（给表加一个版本号字段）** 这个并不是乐观锁的定义，给表加版本号，是**数据库实现乐观锁的一种方式**。

    1. SELECT data AS old_data, version AS old_version FROM …;
    2. 根据获取的数据进行业务操作，得到new_data和new_version
    3. UPDATE SET data = new_data, version = new_version WHERE version = old_version

- 悲观锁和乐观锁使用区别：

  - **响应速度：** 如果需要非常高的响应速度，建议采用乐观锁方案，成功就执行，不成功就失败，不需要等待其他并发去释放锁。
  - **冲突频率：** 如果冲突频率非常高，建议采用悲观锁，保证成功率，如果冲突频率大，乐观锁会需要多次重试才能成功，代价比较大。
  - **重试代价：** 如果重试代价大，建议采用悲观锁。

- MyISAM在执行查询语句（select）前，会自动给涉及的所有表加读锁，在执行增删改操作前，会自动给涉及的表加写锁。

  MySQL的表级锁有两种模式：

  - 表共享读锁
  - 表独占写锁

  **读锁会阻塞写，写锁会阻塞读和写**

- 在MySQL的InnoDB引擎支持行锁，MySQL的行锁是通过索引加载的，也就是说，行锁是加在索引响应的行上的，要是对应的SQL语句没有走索引，则会全表扫描，行锁则无法实现，取而代之的是表锁，此时其它事务无法对当前表进行更新或插入操作。



## 6. 脏读，不可重复读和幻读

- 脏读

  - 当一个事务读取到另外一个事务修改但未提交的数据，而这个数据是有可能回滚的。

- 不可重复读

  - 在数据库访问中，**一个事务范围**内**两个相同的查询**却返回了**不同**数据。这是由于查询时系统中其他事务修改的提交而引起的。

  - **在 InnoDB 存储引擎中，SELECT 操作的不可重复读问题通过 MVCC 得到了解决，而 UPDATE、DELETE 的不可重复读问题是通过 Record Lock 解决的，INSERT 的不可重复读问题是通过 Next-Key Lock（Record Lock + Gap Lock）解决的。**

- 幻读

  - 当一个事物对数据进行查询之后，第二个事物向表中**插入或删除**了一行新数据，此时第一个事物再次进行查询时发现数据与第一次查询时不同。
  - 不可重复读是因为其他事务进行了 UPDATE 操作，幻读是因为其他事务进行了 INSERT 或者 DELETE 操作。

- MySQL是如何解决幻读的？

  - 1. MVCC(快照读)
    2. next-key锁(当前读)

  - 快照读/**非阻塞读（Nonlocking Read）**

    - 我们平时只用使用select就是快照读，这样可以减少加锁所带来的开销。快照读的实现方式：undolog和MVCC
    - 对于 **RC(READ COMMITTED)** 和 **RR(REPEATABLE READ)** 隔离级别的实现就是通过上面的版本控制来完成。两种隔离界别下的核心处理逻辑就是判断所有版本中哪个版本是当前事务可见的处理。针对这个问题InnoDB在设计上增加了**ReadView**的设计，**ReadView**中主要包含当前系统中还有哪些活跃的读写事务
    - Read Committed隔离级别：**每次select都生成一个快照读**
    - Read Repeatable隔离级别：**开启事务后第一个select语句才是快照读的地方，而不是一开启事务就快照读**，并且当前的快照读会一直沿用到当前事务提交，以此来保证可重复读（REPEATABLE READ）。

  - 当前读/**加锁读（Locking Read）** / **阻塞读（Blocking Read）**

    - 当前读，读取的是最新版本，并且对读取的记录加锁，阻塞其他事务同时改动相同记录，避免出现安全问题。

    ```sql
    select * from table where ? lock in share mode; 加 S 锁
    select * from table where ? for update; 加 X 锁
    insert; update; delete;加 X 锁
    ```

    - 当前读在 RR 和 RC 两种隔离级别下的实现也是不一样的：**RC 只加记录锁，RR 除了加记录锁，还会加间隙锁，用于解决幻读问题**



## 7. MySQL 索引

- 索引是帮助MySQL**高效获取数据**的**数据结构**，能**加快数据库的查询速度**，**是存储在磁盘上的文件中的**

- **优势：**

  - **可以提高数据检索的效率，降低数据库的IO成本**，类似于书的目录。

  - 通过**索引列对数据进行排序**，降低数据排序的成本，降低了CPU的消耗。

  - - 被索引的列会自动进行排序，包括【单列索引】和【组合索引】，只是组合索引的排序要复杂一些。
    - 如果按照索引列的顺序进行排序，对应order by语句来说，效率就会提高很多。

  **劣势：**

  - **索引会占据磁盘空间**
  - **索引虽然会提高查询效率，但是会降低更新表的效率**。比如每次对表进行增删改操作，MySQL不仅要保存数据，还有保存或者更新对应的索引文件。

### 7.1 索引类型

  - 主键索引：索引列中的值必须是唯一的，不允许有空值。
  - 普通索引：MySQL中基本索引类型，没有什么限制，允许在定义索引的列中插入重复值和空值。
  - 唯一索引：索引列中的值必须是唯一的，但是允许为空值。
  - 哈希索引：**哈希索引就是采用一定的哈希算法**，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快：
    - 无法用于排序与分组；
    - 只支持精确查找，无法用于部分查找和范围查找。
    - InnoDB 存储引擎有一个特殊的功能叫“自适应哈希索引”，当某个索引值被使用的非常频繁时，会在 B+Tree 索引之上再创建一个哈希索引，这样就让 B+Tree 索引具有哈希索引的一些优点，比如快速的哈希查找。
  - 全文索引：只能在文本类型CHAR,VARCHAR,TEXT类型字段上创建全文索引。字段长度比较大时，如果创建普通索引，在进行like模糊查询时效率比较低，这时可以创建全文索引。MyISAM和InnoDB中都可以使用全文索引。查找条件使用 MATCH AGAINST，而不是普通的 WHERE。全文索引使用倒排索引实现，它记录着关键词到其所在文档的映射。
  - 空间索引：MyISAM 存储引擎支持空间数据索引（R-Tree），可以用于地理数据存储。空间数据索引会从所有维度来索引数据，可以有效地使用任意维度来进行组合查询。
  - 前缀索引：在文本类型如CHAR,VARCHAR,TEXT类列上创建索引时，可以指定索引列的长度，但是数值类型不能指定。
  - 其他(按索引列数量分类)：单列索引和组合索引。组合索引的使用，需要遵循**最左前缀匹配原则（最左匹配原则）**。一般情况下在条件允许的情况下使用组合索引替代多个单列索引使用。

### 7.2 B+树索引和hash索引的区别     

  -  B+树索引适合返回查找，而hash索引适合等值查询 

  -  hash索引无法利用索引完成[排序]()，但是B+树索引可以 

  -  hash索引不支持联合索引的最左匹配规则，但是B+树索引支持 

  -  如果有大量重复键值的情况下，因为存在hash碰撞，hash索引的效率会很低

### 7.3 **MyISAM索引**：非聚簇索引

  - MyISAM的数据文件和索引文件是分开存储的。MyISAM使用B+树构建索引树时，叶子节点中存储的键值为索引列的值，数据为索引所在行的磁盘地址。
  - 主键索引
  - 辅助索引

    - 在 MyISAM 中,辅助索引和主键索引的结构是一样的，没有任何区别，叶子节点的数据存储的都是行记录的磁盘地址。只是主键索引的键值是唯一的，而辅助索引的键值可以重复。
    - 查询数据时，由于辅助索引的键值不唯一，可能存在多个拥有相同的记录，所以即使是等值查询，也需要按照范围查询的方式在辅助索引树中检索数据。

### 7.4 InnoDB索引：聚簇索引

  - **InnoDB的数据和索引存储在一个文件t_user_innodb.ibd中。InnoDB的数据组织方式，是聚簇索引。主键索引的叶子节点会存储数据行，辅助索引只会存储主键值。**

#### 7.4.1 主键索引

- 每个InnoDB表都有一个聚簇索引 ，聚簇索引使用B+树构建，叶子节点存储的数据是整行记录。因为无法把数据行存放在两个不同的地方，所以一个表只能有一个聚簇索引。一般情况下，聚簇索引等同于主键索引，当一个表没有创建主键索引时，InnoDB会自动创建一个ROWID字段来构建聚簇索引。InnoDB创建索引的具体规则如下：

  > 1. 在表上定义主键PRIMARY KEY，InnoDB将主键索引用作聚簇索引。
  > 2. 如果表没有定义主键，InnoDB会选择第一个不为NULL的唯一索引列用作聚簇索引。
  > 3. 如果以上两个都没有，InnoDB 会使用一个6 字节长整型的隐式字段 ROWID字段构建聚簇索引。该ROWID字段会在插入新行时自动递增。

#### 7.4.2 辅助索引：

- 除聚簇索引之外的所有索引都称为辅助索引，InnoDB的辅助索引只会存储主键的值。因此在使用辅助索引进行查找时，需要先查找到主键值，然后再到主索引中进行查找，这个过程也被称作回表查询。

- 底层叶子节点的按照（age，id）的顺序排序，先按照age列从小到大排序，age列相同时按照id列从小到大排序。
- 使用辅助索引需要检索两遍索引：首先检索辅助索引获得主键，然后使用主键到主索引中检索获得记录。

#### 7.4.3 组合索引

- 因为每个select只能选择一个索引，当where条件过多时，考虑建立联合索引，即把多个列作为索引。

- **组合索引的最左前缀匹配原则：使用组合索引查询时，mysql会一直向右匹配直至遇到范围查询(>、<、between、like)就停止匹配。**

- 对于索引(a,b,c)，引擎会先按照a排序，当a相等时，再按照b排序，当b相等时，再按照c排序

  对于索引(a,b,c)来说，能命中的where语句有 

  1.  where a = 1,where a = 1 and b = 1和where a = 1 and b = 1 and c = 1 
  2.  where a like '1%'，对于这个，可能会引出前缀索引

- 在组合索引树中，最底层的叶子节点按照第一列a列从左到右递增排列，但是b列和c列是无序的，b列只有在a列值相等的情况下小范围内递增有序，而c列只能在a，b两列相等的情况下小范围内递增有序。

- 就像下面的查询，B+树会先比较a列来确定下一步应该搜索的方向，往左还是往右。如果a列相同再比较b列。但是如果查询条件没有a列，B+树就不知道第一步应该从哪个节点查起。

- 可以说创建的idx_abc(a,b,c)索引，相当于创建了(a)、（a,b）（a,b,c）三个索引。

#### 7.4.4 前缀索引 

- 因为可能我们索引的字段非常长，这既占内存空间，也不利于维护。所以我们就想，如果只把很长字段的前面的公共部分作为一个索引，就会产生超级加倍的效果。但是，我们需要注意，order by不支持前缀索引 

- 流程是： 

  1. 先计算完整列的选择性 

  ```sql
  select count(distinct col_1)/count(1) from table_1
  ```

  2. 再计算不同前缀长度的选择性 

  ```sql
  select count(distinct left(col_1,4))/count(1) from table_1
  ```

  3. 找到最优长度之后，创建前缀索引 

  ```sql
  create index idx_front on table_1 (col_1(4))
  ```

#### 7.4.5 覆盖索引

- **如果一个索引包含所有需要查询的字段的值，则称之为覆盖索引。**因为在使用辅助索引的时候，我们只可以拿到主键值，相当于获取数据还需要再根据主键查询主键索引再获取到数据。但是试想下这么一种情况，在上面abc_innodb表中的组合索引查询时，如果我只需要abc字段的，那是不是意味着我们查询到组合索引的叶子节点就可以直接返回了，而不需要回表。这种情况就是**覆盖索引**。


### 7.5 聚簇索引与非聚簇索引的区别

- 聚簇索引和非聚簇索引是建立在B+树的基础上 
- 聚簇索引：key为主键，value为其余列的数据。一个表只能有一个聚簇索引；非聚簇索引：除了聚簇索引外的都叫非聚簇索引 
- 对于MyISAM的主键索引来说，它的非聚簇索引是key为主键，value为行号*(不一定)* 
- 对于MyISAM的二级索引来说，它的非聚簇索引是key为其他列，value为行号*(不一定)* 
- 对于InnoDB的二级索引来说，它的非聚簇索引是key为其他列，value是主键 
- 非聚簇索引也叫二级索引 
- 非聚集索引与聚集索引的区别在于非聚集索引的叶子节点不存储表中的数据，而是存储该列对应的主键（行号） 
- 对于InnoDB来说，想要查找数据我们还需要根据主键再去聚集索引中进行查找，这个再根据聚集索引查找数据的过程，我们称为**回表**。第一次索引一般是顺序IO，回表的操作属于随机IO。需要回表的次数越多，即随机IO次数越多，我们就越倾向于使用全表扫描 
- 通常情况下， 主键索引查询只会查一次，而非主键索引（非聚簇索引）需要回表查询多次。当然，如果是覆盖索引的话，查一次即可 
- 注意：MyISAM无论主键索引还是二级索引都是非聚簇索引，而InnoDB的主键索引是聚簇索引，二级索引是非聚簇索引。我们自己建的索引基本都是非聚簇索引

### 7.7 查询在什么情况下不走索引

- 在一条单表查询语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案。这个成本最低的方案就是所谓的执行计划。 优化过程大致如下： 

  1.  根据搜索条件，找出所有可能使用的索引 
  2.  计算全表扫描的代价 
  3.  计算使用不同索引执行查询的代价 
  4.  对比各种执行方案的代价，找出成本最低的那一个

- 假设索引为(a,b,c) 

  -  ASC和DESC索引混合使用的[排序]()：select * from tab order by a, b desc limit 10; 
- 违背最左前缀原则：select * from tab where b = '1'; 
  -  WHERE⼦句中出现非[排序]()使⽤到的索引列：select * from tab d = '1' order by a limit 10; 
- [排序]()列包含非同⼀个索引的列：select * from tab order by a, d limit 10; 
  -  WHERE子句中出现计算：select * from tab where a * 4 = 2; 
- WHERE子句中出现null值：select * from tab where a = null; 
  -  WHERE子句中使用!=或<>操作符：select * from tab where a != 1; 


### 7.8 MySQL如何为表字段添加索引

- 在已建表中添加索引

```sql
CREATE INDEX indexName ON tableName (columnName(length));
```

- 修改表结构添加索引

```sql
添加主键索引:
ALTER TABLE tbl_name ADD PRIMARY KEY (column_list): 该语句添加一个主键，这意味着索引值必须是唯一的，且不能为NULL。

添加唯一索引:
ALTER TABLE tbl_name ADD UNIQUE index_name (column_list): 这条语句创建索引的值必须是唯一的（除了NULL外，NULL可能会出现多次）。

添加普通索引:
ALTER TABLE tbl_name ADD INDEX index_name (column_list): 添加普通索引，索引值可出现多次。

添加全文索引(适用于MyISAM，InnoDB 5.6+):
ALTER TABLE tbl_name ADD FULLTEXT index_name (column_list):该语句指定了索引为 FULLTEXT ，用于全文索引。

添加联合索引:
ALTER TABLE `table_name` ADD INDEX index_name ( `column1`, `column2`, `column3` )
```

- 创建表时直接指定

```sql
CREATE TABLE mytable(  
 
ID INT NOT NULL,   
 
username VARCHAR(16) NOT NULL,  
 
INDEX [indexName] (username(length))  
 
);  
```

- 删除索引的语法

```sql
DROP INDEX [indexName] ON mytable; 
ALTER TABLE t_user_action_log DROP INDEX index_ip_addr;
```

- 查看索引

```
SHOW INDEX FROM tableName;
```

### 7.9 如何选择索引

- 建立索引的时候应该遵循以下原则：
  - 在经常需要搜索的列上建立索引，可以加快搜索的速度。
  - 在作为主键的列上创建索引，强制该列的唯一性，并组织表中数据的排列结构。
  - 在经常使用表连接的列上创建索引，这些列主要是一些外键，可以加快表连接的速度。
  - 在经常需要根据范围进行搜索的列上创建索引，因为索引已经排序，所以其指定的范围是连续的。
  - 在经常需要排序的列上创建索引，因为索引已经排序，所以查询时可以利用索引的排序，加快排序查询。
  - 在经常使用 WHERE 子句的列上创建索引，加快条件的判断速度。

## 8. B+树索引

- 二叉查找树(BST)：不平衡

  - 二叉查找树(BST，Binary Search Tree)，也叫二叉排序树，在二叉树的基础上需要满足：任意节点的左子树上所有节点值不大于根节点的值，任意节点的右子树上所有节点值不小于根节点的值。
  - 因为此时查询时间取决于树高，平均时间复杂度是O(lgn)。然而，BST可能长歪而变得不平衡，此时BST退化为链表，时间复杂度退化为O(n)。

- 平衡二叉树(AVL)：旋转耗时

  - 一般是用平衡因子差值决定并通过旋转来实现，左右子树树高差不超过1，那么和红黑树比较它是严格的平衡二叉树，平衡条件非常严格（树高差只有1），只要插入或删除不满足上面的条件就要通过旋转来保持平衡。由于旋转是非常耗费时间的。所以 AVL 树适用于插入/删除次数比较少，但查找多的场景。

- 红黑树：树太高

  - 通过对从根节点到叶子节点路径上各个节点的颜色进行约束，确保没有一条路径会比其他路径长2倍，因而是近似平衡的。所以相对于严格要求平衡的AVL树来说，它的旋转保持平衡次数较少。适合，查找少，插入/删除次数多的场景。
  - 对于数据在内存中的情况（TreeMap和HashMap），红黑树的表现是非常优异的。但是对于数据在磁盘等辅助存储设备中的情况（如MySQL等数据库），红黑树并不擅长，因为红黑树长得还是太高了。当数据在磁盘中时，磁盘IO会成为最大的性能瓶颈，设计的目标应该是尽量减少IO次数；而树的高度越高，增删改查所需要的IO次数也越多，会严重影响性能。

- B树：为磁盘而生

  - B树也称B-树(其中-不是减号)，是多叉平衡查找树，与二叉树相比，B树的每个非叶节点可以有多个子树。因此，当总节点数量相同时，B树的高度远远小于AVL树和红黑树(B树是一颗“矮胖子”)，磁盘IO次数大大减少。
  - 主要特点：

  1. B树的节点中存储着多个元素，每个内节点有多个分叉。
    2. 节点中的元素包含键值和数据，节点中的键值从小到大排列。也就是说，在所有的节点都储存数据。
    3. 父节点当中的元素不会出现在子节点中。
    4. 所有的叶子结点都位于同一层，叶节点具有相同的深度，叶节点之间没有指针连接。

  - B树的问题：
    - B树不支持范围查询的快速查找，你想想这么一个情况如果我们想要查找10和35之间的数据，查找到15之后，需要回到根节点重新遍历查找，需要从根节点进行多次遍历，查询效率有待提高。
    - 如果data存储的是行记录，行的大小随着列数的增多，所占空间会变大。这时，一个页中可存储的数据量就会变少，树相应就会变高，磁盘IO次数就会变大。

- B+树

  - B+树也是多叉平衡查找树，其与B树的区别主要在于：
    - B树中每个节点（包括叶节点和非叶节点）都存储数据，B+树中只有叶子节点存储数据，非叶节点只存储键值。
    - 内部节点中的 key 都按照从小到大的顺序排列，对于内部节点中的一个 key，左子树中的所有 key 都小于它，右子树中的 key 都大于等于它，叶子节点的记录也是按照从小到大排列的。
    - 叶子节点之间使用双向指针连接，最底层的叶子节点形成了一个双向有序链表。
    - B树中一条记录只会出现一次，不会重复出现，而B+树的键则可能重复重现——一定会在叶节点出现，也可能在非叶节点重复出现。
    - B树中的非叶节点，记录数比子节点个数少1；而B+树中记录数与子节点个数相同。
    - **可以看到B+树可以保证等值和范围查询的快速查找，MySQL的索引就采用了B+树的数据结构。**

  - B+树与B树比较：
    - 更少的IO次数：B+树的非叶节点只包含键，而不包含真实数据，因此每个节点存储的记录个数比B数多很多（即阶m更大），因此B+树的高度更低，访问时所需要的IO次数更少。此外，由于每个节点存储的记录数更多，所以对访问局部性原理的利用更好，缓存命中率更高。
    - 更适于范围查询：在B树中进行范围查询时，首先找到要查找的下限，然后对B树进行中序遍历，直到找到查找的上限；而B+树的范围查询，只需要对链表进行遍历即可。
    - 更稳定的查询效率：B树的查询时间复杂度在1到树高之间(分别对应记录在根节点和叶节点)，而B+树的查询复杂度则稳定为树高，因为所有数据都在叶节点。由于非叶子结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当。

  - B+树也存在劣势：由于键会重复出现，因此会占用更多的空间。

## 9. 数据库三大范式

- 第一范式： 所有字段值都是不可分解的原子值 。
  - 例如有一个列是电话号码一个人可能有一个办公电话一个移动电话。第一范式就需要拆开成两个属性。 
- 第二范式：非主属性完全函数依赖于候选键。
  - 如PersonID，ProductID，ProductName，PersonName可以看到，OrderID和ProductID是联合主键，但是ProductName是依赖于ProductID的，只依赖了部分主键，没有依赖全部主键。需要拆分成三个表：PersonID, PersonName,ProductID, ProductName和PersonID, ProductID 
- 第三范式： 每一列数据都和主键直接相关，而不能间接相关。
  -  如OrderID，ProductID，ProductName，OrderID是主键，但是ProductID依赖了OrderID，而ProductName依赖了ProductID，等于说是间接依赖了OrderID，所以需要拆分为两个表：OrderID, ProductID和ProductID, ProductName

## 10. 多版本并发控制(MVCC)

- 多版本并发控制（Multi-Version Concurrency Control, MVCC）是 MySQL 的 InnoDB 存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别。而未提交读隔离级别总是读取最新的数据行，无需使用 MVCC。可串行化隔离级别需要对所有读取的行都加锁，单纯使用 MVCC 无法实现。

- InnoDB的MVCC是通过在每行记录后面保存两个隐藏的列来实现的，这两个值一个记录这行数据创建的版本号，另外一个记录这行数据被删除时的版本号。**一个保存了行的事务ID（DB_TRX_ID），一个保存了行的回滚指针（DB_ROLL_PT）**。每开始一个新的事务，都会自动递增产 生一个新的事务id。事务开始时刻的会把事务id放到当前事务影响的行事务id中，当查询时需要用当前事务id和每行记录的事务id进行比较。

- **DB_TRX_ID**: 6字节`DB_TRX_ID`字段，表示最后更新的事务id(update,delete,insert)。
  此外，删除在内部被视为更新，其中行中的特殊位被设置为将其标记为已软删除。

- **DB_ROLL_PTR**: 7字节回滚指针，指向前一个版本的undolog记录，组成undo链表。如果更新了行，则撤消日志记录包含在更新行之前重建行内容所需的信息。

- 在实际操作中，存储的并不是时间，而是事务的版本号，每开启一个新事务，事务的版本号就会递增。在可重读Repeatable reads事务隔离级别下：

  - SELECT时，读取创建版本号<=当前事务版本号，删除版本号为空或>当前事务版本号。
  - INSERT时，保存当前事务版本号为行的创建版本号
  - DELETE时，保存当前事务版本号为行的删除版本号
  - UPDATE时，插入一条新纪录，保存当前事务版本号为行创建版本号，同时保存当前事务版本号到原来删除的行


### 10.1 快照读/**非阻塞读（Nonlocking Read）**

- 我们平时只用使用select就是快照读，读取的是记录的可见版本 (有可能是历史版本)，不用加锁。这样可以减少加锁所带来的开销。快照读的实现方式：undolog和MVCC
- 对于 **RU(READ UNCOMMITTED)** 隔离级别下，所有事务直接读取数据库的最新值即可，和 **SERIALIZABLE** 隔离级别，所有请求都会加锁，同步执行。所以这对这两种情况下是不需要使用到 **Read View** 的版本控制。
- 对于 **RC(READ COMMITTED)** 和 **RR(REPEATABLE READ)** 隔离级别的实现就是通过上面的版本控制来完成。两种隔离界别下的核心处理逻辑就是判断所有版本中哪个版本是当前事务可见的处理。针对这个问题InnoDB在设计上增加了**ReadView**的设计，**ReadView**中主要包含当前系统中还有哪些活跃的读写事务
- Read Committed隔离级别：**每次select都生成一个快照读**
- Read Repeatable隔离级别：**开启事务后第一个select语句才是快照读的地方，而不是一开启事务就快照读**，并且当前的快照读会一直沿用到当前事务提交，以此来保证可重复读（REPEATABLE READ）。

### 10.2 当前读/**加锁读（Locking Read）** / **阻塞读（Blocking Read）**

  - 当前读，读取的是最新版本，并且对读取的记录加锁，阻塞其他事务同时改动相同记录，避免出现安全问题。

  ```sql
  select * from table where ? lock in share mode; 加 S 锁
  select * from table where ? for update; 加 X 锁
  insert; update; delete;加 X 锁
  ```

  - 当前读在 RR 和 RC 两种隔离级别下的实现也是不一样的：**RC 只加记录锁，RR 除了加记录锁，还会加间隙锁，用于解决幻读问题**
  - 利用select * for update 可以锁表/锁行，仅适用于InnoDB，且必须在事务处理模块(BEGIN/COMMIT)中才能生效
    - 例1: (明确指定主键，并且有此笔资料，row lock)
      SELECT * FROM wallet WHERE id=’3′ FOR UPDATE;
    - 例2: (明确指定主键，若查无此笔资料，无lock)
      SELECT * FROM wallet WHERE id=’-1′ FOR UPDATE;
    - 例3: (无主键，table lock)
      SELECT * FROM wallet WHERE name=’Mouse’ FOR UPDATE;
    - 例4: (主键不明确，table lock)
      SELECT * FROM wallet WHERE id<>’3′ FOR UPDATE;
    - 例5: (主键不明确，table lock)
      SELECT * FROM wallet WHERE id LIKE ‘3’ FOR UPDATE;
  - 当前读使用next-key锁(行记录锁+Gap间隙锁)实现，只有在Read Repeatable、Serializable隔离级别才有，就是锁定范围空间的数据。
    - 对主键或唯一索引，如果当前读时，where条件全部精确命中(=或者in)，这种场景本身就不会出现幻读，所以只会加行记录锁。
    - 没有索引的列，当前读操作时，会加全表gap锁，生产环境要注意。
    - 非唯一索引列，如果where条件部分命中(>、<、like等)或者全未命中，则会加附近Gap间隙锁。例如，某表数据如下，非唯一索引2,6,9,9,11,15。如下语句要操作非唯一索引列9的数据，gap锁将会锁定的列是(6,11]，该区间内无法插入数据。

|          | 快照读               | 当前读                           |
| -------- | -------------------- | -------------------------------- |
| 读未提交 |                      | 读取最新版本                     |
| 读已提交 | 读取最新一份快照     | 读取最新版本，并加记录锁         |
| 可重复读 | 读取事务开始时的快照 | 读取最新版本，并加记录锁和间隙锁 |
| 序列化   |                      | 读取最新版本，并加记录锁和间隙锁 |

- undo log
  - Undo Log是为了实现事务的原子性，在MySQL数据库InnoDB存储引擎中，还用了Undo Log来实现多版本并发控制(简称：MVCC)。
  - `undo log`主要有两个作用：回滚和多版本控制(MVCC)
  - `undo log`主要存储的也是逻辑日志，比如我们要`insert`一条数据了，那`undo log`会记录的一条对应的`delete`日志。我们要`update`一条记录时，它会记录一条对应**相反**的update记录。
  - 因为`undo log`存储着修改之前的数据，相当于一个**前版本**，MVCC实现的是读写不阻塞，读的时候只要返回前一个版本的数据就行了。

## 11. **数据库崩溃时事务的恢复机制（REDO日志和UNDO日志）**

### 11.1 binlog

- `binlog`记录了数据库表结构和表数据变更，存储着每条变更的`SQL`语句，不会记录`select`
- 主要有两个作用：**复制和恢复数据**
  - 主从服务器需要保持数据的一致性，通过`binlog`来同步数据。
  - 如果整个数据库的数据都被删除了，`binlog`存储着所有的数据变更情况，那么可以通过`binlog`来对数据进行恢复。

### 11.2 redo log

-  记录了数据操作在物理层面的修改，如果写入内存成功，但数据还没真正刷到磁盘，如果此时的数据库挂了，我们可以靠`redo log`来恢复内存的数据，这就实现了持久性
-  `redo log`的作用是为**持久化**而生的。写完内存，如果数据库挂了，那我们可以通过`redo log`来恢复内存还没来得及刷到磁盘的数据，将`redo log`加载到内存里边，那内存就能恢复到挂掉之前的数据了。`redo log` 存储的是物理数据的变更，如果我们内存的数据已经刷到了磁盘了，那`redo log`的数据就无效了。所以`redo log`不会存储着**历史**所有数据的变更，**文件的内容会被覆盖的**。

### 11.3 binlog和redo log区别

- redo log是物理日志，记录的是“在某个数据页上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，记录的是`update/delete/insert`这样的SQL语句
- redo log是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用
- binlog可以作为恢复数据使用，主从复制搭建，redo log作为异常宕机或者介质故障后的数据恢复使用
- redo log是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写”是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志
- MySQL通过**两阶段提交**来保证`redo log`和`binlog`的数据是一致的。过程：
  - 引擎将新记录更新到内存，并将更新记录写入redo log，redo log处于prepare状态，随时可以提交事务；
  - 执行器生成bin log写入磁盘；
  - 执行器调用引擎提交事务接口，把redo log成成commit状态，更新完成。
  - 注意：Mysql的redolog模块写入拆成2步走，prepare和commit，称为两阶段提交。 整个过程为1、redolog的prepare状态 2、binlog的写入 3、redolog的commit状态，保证Mysql的可靠性。
    - 对于活跃的事务，直接回滚
    - 对于redo中是Prepare状态的事务，如果binlog中已记录完成则提交，否则回滚事务

## 12. sql语法

- select 查询结果    如: [学号,平均成绩：组函数avg(成绩)]
- from 从哪张表中查找数据   如:[涉及到成绩：成绩表score]
- where 查询条件    如:[b.课程号='0003' and b.成绩>80]
- group by 分组    **使用GROUP BY子句时，SELECT子句中只能有聚合键、聚合函数、常数。**

```sql
select emp_no, count(salary) as t
from salaries
group by emp_no
having count(salary) > 15
```

- having 对分组结果指定条件    如:[大于60分]
- order by 对查询结果排序    如:[增序: 成绩  ASC / 降序: 成绩 DESC];
- limit   使用limt子句返回topN（对应这个问题返回的成绩前两名）如:[ limit  2 ==>从0索引开始读取2个]
  limit==>从0索引开始 [0,N-1]

```sql
select * from employees order by hire_date desc limit 2,1;
```

- 组函数: 去重 distinct()  统计总数sum()   计算个数count()  平均数avg()  最大值max() 最小数min() 

- 多表连接: 内连接(省略默认inner) join ...on..左连接left join tableName as b on a.key ==b.key右连接right join  连接union(无重复(过滤去重))和union all(有重复[不过滤去重])

  ```sql
  select s.*, d.dept_no
  from dept_manager as d
  left join salaries as s
  on d.emp_no =  s.emp_no
  order by s.emp_no asc
  ```

- 内连接INNER JOIN求两个表的**交集**

- 左连接LEFT JOIN的含义就是求两个表A表和B表的**交集外加左表剩下的数据**。

- 右连接RIGHT JOIN就是求两个表**A和B表的交集外加右表B剩下的数据**。

- 外连接FULL OUTER JOIN就是求两个表**A和B集合的并集**。另外MySQL不支持OUTER JOIN，但是我们可以对左连接和右连接的结果做 **UNION** 操作来实现。MySQL UNION 操作符用于连接两个以上的 SELECT 语句的结果组合到一个结果集合中。多个 SELECT 语句会删除重复的数据。

- LEFT JOIN EXCLUDING INNER JOIN（左连接-内连接）


```sql
SELECT <select_list> 
FROM Table_A A
LEFT JOIN Table_B B
ON A.Key = B.Key
WHERE B.Key IS NULL
```

- OUTER JOIN EXCLUDING INNER JOIN（外连接-内连接）

```sql
SELECT <select_list>
FROM Table_A A
FULL OUTER JOIN Table_B B
ON A.Key = B.Key
WHERE A.Key IS NULL OR B.Key IS NULL
```

## 13. 页和行的大小

- MySQL表具有65,535字节的最大行大小限制，即使存储引擎能够支持更大的行也是如此。
- 对于默认的16KB InnoDB页大小，最大行大小略小于8KB 。对于64KB页，最大行大小略小于16KB。如果包含可变长度列(例如：text)的InnoDB 行超过最大行大小，InnoDB选择可变长度列进行页外存储。
- mysql innodb存放多少量级的数据：innodb默认页大小为16k，假如主键id为bigint类型，长度为8字节，而指针大小在InnoDB源码中设置为6字节。这样算下来就是 16384 / 14 = 1170，就是说一个页上可以存放1170个指针。假如一行数据大小是1k，那么理论上一页就可以放16条数据。一个指针指向一个存放记录的页，一个页里可以放16条数据，那么一颗高度为2的B+树就可以存放 1170 * 16=18720 条数据。同理，高度为3的B+树，就可以存放 1170 * 1170 * 16 = 21902400 条记录。



## 14. MySQL调优

### 14.1 排除缓存干扰

- 如果是8.0之下的版本，需要排除缓存的干扰。
- 开启缓存，那每次请求的查询语句和结果都会以key-value的形式缓存在内存中
- 缓存失效比较频繁的原因就是，只要我们一对表进行更新，那这个表所有的缓存都会被清空
- 在执行SQL的时候，记得加上SQL NoCache去跑SQL，这样跑出来的时间就是真实的查询时间了。

### 14.2 Explain

- 通过`explain`语句来查看执行计划，优化sql语句

  | 1    | EXPLAIN SELECT * FROM employees.titles WHERE emp_no='10001' AND title='Senior Engineer' AND from_date='1986-06-26'; |
  | ---- | ------------------------------------------------------------ |
  |      |                                                              |

  | id   | select_type | table  | partitions | type  | possible_keys | key     | key_len | ref               | filtered | rows | Extra |
  | ---- | ----------- | ------ | ---------- | ----- | ------------- | ------- | ------- | ----------------- | -------- | ---- | ----- |
  | 1    | SIMPLE      | titles | null       | const | PRIMARY       | PRIMARY | 59      | const,const,const | 10       | 1    |       |

- explain命令输出的结果有10列：`id、select_type、table、type、possible_keys、key、key_len、ref、rows、Extra`

- id：包含一组数字，表示查询中执行SELECT子句或操作表的**顺序**。在id列上也会有几种情况：

  - 如果id相同执行顺序由上至下。
  - 如果id不相同，id的序号会递增，id值越大优先级越高，越先被执行。(一般有子查询的SQL语句id就会不同)

- **select_type**：表示select的类型，select_type属性下有好几种类型：

  - **SIMPLLE**：简单查询，该查询不包含 UNION 或子查询
  - **PRIMARY**：如果查询包含UNION 或子查询，则**最外层的查询**被标识为PRIMARY
  - UNION：表示此查询是 UNION 中的第二个或者随后的查询
  - DEPENDENT：UNION 满足 UNION 中的第二个或者随后的查询，其次取决于外面的查询
  - UNION RESULT：UNION 的结果
  - **SUBQUERY**：子查询中的第一个select语句(该子查询不在from子句中)
  - DEPENDENT SUBQUERY：子查询中的 第一个 select，同时取决于外面的查询
  - **DERIVED**：包含在from子句中子查询(也称为派生表)
  - UNCACHEABLE SUBQUERY：满足是子查询中的第一个 select 语句，同时意味着 select 中的某些特性阻止结果被缓存于一个 Item_cache 中
  - UNCACHEABLE UNION：满足此查询是 UNION 中的第二个或者随后的查询，同时意味着 select 中的某些特性阻止结果被缓存于一个 Item_cache 中

- table：table表示查询涉及的表或衍生的表

- **type**：type表示MySQL在表中找到所需行的方式，又称“访问类型”：

  - `system`: 表中只有一条数据， 这个类型是特殊的 const 类型。
  - `const`: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可。当MySQL对查询某部分进行优化，并转换为一个常量时，使用这些类型访问。
    如将主键置于where列表中，MySQL就能将该查询转换为一个常量。
  - `eqref`: 类似ref，区别就在使用的索引是唯一索引，对于每个索引键值，表中只有一条记录匹配，简单来说，就是多表连接中使用primary key或者 unique key作为关联条件。
  - `ref`: 此类型通常出现在多表的 join 查询，针对于非唯一或非主键索引，或者是使用了最左前缀规则索引的查询。表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值。
  - `range`: 表示使用索引范围查询，通过索引字段范围获取表中部分数据记录。这个类型通常出现在 =, <>, >, >=, <, <=, IS NULL, <=>, BETWEEN, IN() 操作中。
  - `index`: 表示全索引扫描(full index scan)，index与ALL区别为index类型只遍历索引树。
  - `ALL`: 表示全表扫描，MySQL将遍历全表以找到匹配的行。
  - 通常来说, 不同的 type 类型的性能关系如下：`ALL < index < range < ref < eqref < const < system` 

- **possible_key**：MySQL能使用哪个索引在表中找到记录，查询涉及到的字段上如果存在索引则该索引将被列出，但不一定被查询使用。

- **key**：MySQL实际决定使用的键（索引），如果没有选择索引，键是NULL。

- **key_len**：表示查询优化器使用了索引的字节数，这个字段可以评估组合索引是否完全被使用。

  - key_len 的计算规则如下:
    - 字符串
      - char(n): n 字节长度
      - varchar(n): 如果是 utf8 编码, 则是 3 *n + 2字节; 如果是 utf8mb4 编码, 则是 4* n + 2 字节.
    - 数值类型:
      - TINYINT: 1字节
      - SMALLINT: 2字节
      - MEDIUMINT: 3字节
      - INT: 4字节
      - BIGINT: 8字节
    - 时间类型
      - DATE: 3字节
      - TIMESTAMP: 4字节
      - DATETIME: 8字节
    - 字段属性: NULL 属性 占用一个字节. 如果一个字段是 NOT NULL 的, 则没有此属性.

- **ref**：表示上述表的连接匹配条件，即哪些列或常量被用于查找索引列上的值。

- **rows**：MySQL根据表统计信息，以及索引选用的情况，找到所需记录需要读取的行数。这个行数是估算的值，实际行数可能不同。这个值非常直观的显示 sql 效率好坏， 原则上 rows 越少越好。

- **extra**：explain 中的很多额外的信息会在 extra 字段显示, 常见的有以下几种内容:

  - `using filesort` ：表示 mysql 需额外的排序操作，不能通过索引顺序达到排序效果。一般有 using filesort都建议优化去掉，因为这样的查询 cpu 资源消耗大。
  - `using index`：覆盖索引扫描，表示查询在索引树中就可查找所需数据，不用扫描表数据文件，往往说明性能不错。
  - `using temporary`：查询有使用临时表, 一般出现于排序， 分组和多表 join 的情况， 查询效率不高，建议优化。
  - `using where` ：表名使用了where过滤。

### 14.3 覆盖索引

- 避免回表，减少树的搜索次数，显著提升查询性能
  - 在InnoDB的存储引擎中，使用辅助索引查询的时候，因为辅助索引叶子节点保存的数据不是当前记录的数据而是当前记录的主键索引，索引如果需要获取当前记录完整数据就必然需要根据主键值从主键索引继续查询。这个过程我们成位回表。想想回表必然是会消耗性能影响性能。那如何避免呢？
  - 使用索引覆盖，举个例子：现有User表（id(PK),name(key),sex,address,hobby...）如果在一个场景下，`select id,name,sex from user where name ='zhangsan';`这个语句在业务上频繁使用到，而user表的其他字段使用频率远低于它，在这种情况下，如果我们在建立 name 字段的索引的时候，不是使用单一索引，而是使用联合索引（name，sex）这样的话再执行这个查询语句是不是根据辅助索引查询到的结果就可以获取当前语句的完整数据。这样就可以有效地避免了回表再获取sex的数据。
  - **这里就是一个典型的使用覆盖索引的优化策略减少回表的情况。**

### 14.4 联合索引

- 联合索引又叫复合索引。两个或更多个列上的索引被称作复合索引。
- 对于复合索引：**Mysql从左到右的使用索引中的字段，一个查询可以只使用索引中的一部分，但只能是最左侧部分。**例如索引是key index （a,b,c）。可以支持a | a,b| a,b,c 3种组合进行查找，但不支持 b,c进行查找 。**当最左侧字段是常量引用时，索引就十分有效。**
- **创建复合索引时，应该仔细考虑列的顺序。** **对索引中的所有列执行搜索或仅对前几列执行搜索时，复合索引非常有用；** **仅对后面的任意列执行搜索时，复合索引则没有用处。**
- **联合索引**，在建立索引的时候，尽量在多个单列索引上判断下是否可以使用联合索引。联合索引的使用不仅可以节省空间，还可以更容易的使用到索引覆盖。
- **联合索引的创建原则**，在创建联合索引的时候因该把频繁使用的列、区分度高的列放在前面，频繁使用代表索引利用率高，区分度高代表筛选粒度大，这些都是在索引创建的需要考虑到的优化场景，也可以在常需要作为查询返回的字段上增加到联合索引中，如果在联合索引上增加一个字段而使用到了覆盖索引，那我建议这种情况下使用联合索引。
- **联合索引的使用**
  1. 考虑当前是否已经存在多个可以合并的单列索引，如果有，那么将当前多个单列索引创建为一个联合索引。
  2. 当前索引存在频繁使用作为返回字段的列，这个时候就可以考虑当前列是否可以加入到当前已经存在索引上，使其查询语句可以使用到覆盖索引。
- 索引失效的条件

  - 在索引列上做任何操作（计算、函数、（自动or手动）类型转换），会导致索引失效而转向全表扫描
  - 存储引擎不能使用索引范围条件右边的列，**select** * **from** myTest **where** a=3 **and** b>7 **and** c=3; *---- b范围值，断点，阻塞了c的索引*，a用到了，b也用到了，c没有用到，这个地方b是范围值，也算断点，只不过自身用到了索引。
  - 尽量使用覆盖索引（只访问索引的查询（索引列和查询列一致）），减少select *
  - mysql在使用不等于（！=或者<>）的时候无法使用索引会导致全表扫描
  - is null,is not null也无法使用索引
  - like以通配符开头（’%abc…’）mysql索引失效会变成全表扫描的操作。通过覆盖索引解决：当需要两边都使用%来模糊查询时，只有当这个作为模糊查询的条件字段（例子中的name）以及所想要查询出来的数据字段（例子中的 id & name & age）都在索引列上时，才能真正使用索引，否则，索引失效全表扫描（比如查询字段多了一个 salary ，而又不在索引列上）

### 14.5 最左匹配原则

- mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配

### 14.6 索引下推(ICP)

- MySQL 5.6开始支持ICP，不支持ICP之前，当进行二级索引查询时，首先存储引擎根据索引来查找数据，然后在server层根据where条件来过滤，扫描了大量不必要的数据，增加了数据库IO操作。
- 在支持ICP后，存储引擎在取出索引数据的同时，判断是否可以进行where条件过滤，将where的部分过滤操作放在存储引擎层提前过滤掉不必要的数据，只有当索引符合条件时才会将数据检索出来返回给server层 ，减少了不必要数据被扫描带来的IO开销。
- 在InnoDB中只针对二级索引有效
- **索引条件下推优化可以减少存储引擎查询基础表的次数，也可以减少MySQL服务器从存储引擎接收数据的次数。**

### 14.7 唯一索引和普通索引的选择

- 唯一索引和普通索引在读取的时候效率基本差不多，普通索引差了一点点。主要是判断和特殊情况下的一次IO 
- 写入的时候，普通索引可以利用change buffer，适合写多读少，比唯一索引要快 
- 因此，对于写多读少的业务来说，页面在写完以后马上被访问到的概率比较小，此时change buffer的使用效果最好，这种业务模型常见的就是账单类、日志类的系统。
- 反过来，假设一个业务的更新模式是写入之后马上会做查询，那么即使满足了条件，将更新先记录在change buffer，但之后由于马上要访问这个数据页，会立即触发merge过程。这样随机访问IO的次数不会减少，反而增加了change buffer的维护代价，所以，对于这种业务模式来说，change buffer反而起到了副作用。

#### 14.7.1 change buffer

- 当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。
- 在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作，通过这种方式就能保证这个数据逻辑的正确性。
- 将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。
- 除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。

- 如果能够将更新操作先记录在change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用buffer pool的，所以这种方式还能够避免占用内存，提高内存利用率。将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一，change buffer因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。
- 对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。要判断表中是否存在这个数据，而这必须要将数据页读入内存才能判断，如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了。
- 只有普通索引可以使用change buffer，change buffer用的是buffer pool里的内存，因此不能无限增大，change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置，这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。

### 14.8 前缀索引

- 可以定义字符串的一部分作为索引。默认地，如果创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。使用前缀索引，定义好长度，就可以做到既节省空间，又不用额外增加太多的查询成本。
- 可以采用hash，倒序，或者删减字符串等方法建立区分度
- 把字段hash为另外一个字段存起来，每次校验hash就好了，hash的索引也不大。
- 就比如本来是www.aobing@qq,com这样的邮箱，前面的`www.`基本上是没任何区分度的，可以substring()函数截取掉前面的，然后建立索引。
- 身份证都是区域开头的，同区域的人很多，可以使用REVERSE()函数翻转一下，区分度可能就高了。

### 14.9 条件字段函数操作

- 对索引字段做函数操作，可能会破坏索引值的有序性，因此优化器就决定放弃走树搜索功能。
- 用一些取巧的方法，比如 select * from tradelog where id + 1 = 10000 就走不上索引，select * from tradelog where id = 9999就可以。
- 隐式类型转换也用不上索引，select * from t where id = 1，如果id是字符类型的，1是数字类型的，explain会发现走了全表扫描，根本用不上索引。因为MySQL底层会对你的比较进行转换，相当于加了 CAST( id AS signed int) 这样的一个函数，上面说过函数会导致走不上索引。
- 隐式字符编码转换也用不上索引，如果两个表的字符集不一样，一个是utf8mb4，一个是utf8，因为utf8mb4是utf8的超集，所以一旦两个字符比较，就会转换为utf8mb4再比较。转换的过程相当于加了CONVERT(id USING utf8mb4)函数，那又回到上面的问题了，用到函数就用不上索引了。

## 15. MySQL底层

### 15.1 基础框架

- 1、连接器管理： 首先是数据库连接器，主要负责和客户端建立连接、权限获取、管理连接等，由于整个建连的过程比较复杂，所以尽量使用长连接。如果数据库发生异常后为了快速恢复，可重启系统重新建立连接
- 2、Mysql缓存：mysql请求首先看缓存数据，key为sql语句value为查询的结果，如果存在则直接返回。如果没有则直接往下走。注意：mysql缓存对于一些静态数据比较适合，对于实时性高的数据最好不要使用。
- 3、分析器： 对你执行的sql语句进行解析，首先是词法分析包括一些关键字识别，然后语法分析，查看这条语句是否符合mysql语句
- 4、优化器：通过你的语句分析，发现那些查询命中索引，还有表之间的连接顺序等
- 5、执行器：通过上面一系列的验证，使用引擎提供的接口。经过不断的执行将查询的结果存放在结果集中，通过explain可以看到执行器具体扫描了多少行。

### 15.2 **DML语句的执行流程**

- ```sql
  mysql> UPDATE T SET age = age+1 WHERE id = 1;
  ```

  1. 执行器先找引擎找id=1这行记录。id为主键，引擎通过索引找到记录；
  2. 执行器拿到行记录，对age+1，调用引擎写接口，更新数据；
  3. 引擎将新记录更新到内存，并将更新记录写入redo log，redo log处于prepare状态，随时可以提交事务；
  4. 执行器生成bin log写入磁盘；
  5. 执行器调用引擎提交事务接口，把redo log成成commit状态，更新完成。

- 注意：Mysql的redolog模块写入拆成2步走，prepare和commit，称为两阶段提交。 整个过程为1、redolog的prepare状态 2、binlog的写入 3、redolog的commit状态，保证Mysql的可靠性。

  - 对于活跃的事务，直接回滚
  - 对于redo中是Prepare状态的事务，如果binlog中已记录完成则提交，否则回滚事务

### 15.3 MySQL查询过程

- 连接器：我们要进行查询，第一步就是先去链接数据库，那这个时候就是连接器跟我们对接。他负责跟客户端建立链接、获取权限、维持和管理连接。链接的时候会经过TCP握手，然后身份验证，然后我们输入用户名密码就好了。

- 查询缓存：MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。查询的时候就会拿着语句先去缓存中查询，如果能够命中就返回缓存的value，如果不命中就执行后面的阶段。

- 分析器：会先做**词法分析**，你的语句有这么多单词、空格，MySQL就需要识别每个字符串所代表的是什么，是关键字，还是表名，还是列名等等。然后就开始**语法分析**，根据词法分析的结果，语法分析会判断你sql的对错，错了会提醒你的，并且会提示你哪里错了。

- 优化器：在一条单表查询语句真正执行之前，MySQL的查询优化器会找出执行该语句所有可能使用的方案，对比之后找出成本最低的方案。这个成本最低的方案就是所谓的执行计划。 优化过程大致如下： 

  1.  根据搜索条件，找出所有可能使用的索引 
  2.  计算全表扫描的代价 
  3.  计算使用不同索引执行查询的代价 
  4.  对比各种执行方案的代价，找出成本最低的那一个

- 执行器：在完成解析和优化阶段以后，MySQL会生成对应的执行计划，查询执行引擎根据执行计划给出的指令逐步执行得出结果。整个执行过程的大部分操作均是通过调用存储引擎实现的接口来完成，这些接口被称为handler API。查询过程中的每一张表由一个handler实例表示，实际上，MySQL在查询优化阶段就为每一张表创建了一个handler实例，优化器可以根据这些实例的接口来获取表的相关信息，包括表的所有列名、索引统计信息等。

- 总结下mysql整个查询流程如下: 

  1.客户端向MySQL服务器发送一条查询请求

  2.服务器首先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。否则进入下一级段

  3.服务器进行SQL解析、预处理、再由优化器生成对应的执行计划

  4.MySQL根据执行计划，调用存储引擎的API来执行查询

  5.将结果返回给客户端，同时缓存查询结果

## 16. 表连接和子查询

- **子查询不一定需要两个表有关联字段，而连接查询必须有字段关联（所谓的主外键关系）**
- 表关联的效率要高于子查询，因为子查询走的是笛卡尔积
- 表关联可能有多条记录，子查询只有一条记录，如果需要唯一的列，最好走子查询
- 对于数据量多的肯定是用连接查询快些，原因：因为子查询会多次遍历所有的数据（视你的子查询的层次而定），而连接查询只会遍历一次。
- 执行子查询时，MYSQL需要创建临时表，查询完毕后再删除这些临时表，所以，子查询的速度会受到一定的影响，这里多了一个创建和销毁临时表的过程。

## 17. **count(\*)、count(1)、count(column)的区别**

- count(*)对行的数目进行计算,包含NULL

- count(column)对特定的列的值具有的行数进行计算,不包含NULL值。

- count()还有一种使用方式,count(1)这个用法和count(*)的结果是一样的。

- 1.任何情况下SELECT COUNT(*) FROM tablename是最优选择;

  2.尽量减少SELECT COUNT(*) FROM tablename WHERE COL = ‘value’ 这种查询;

  3.杜绝SELECT COUNT(COL) FROM tablename WHERE COL2 = ‘value’ 的出现。

  - 如果表没有主键,那么count(1)比count(*)快。
  - 如果有主键,那么count(主键,联合主键)比count(*)快。
  - 如果表只有一个字段,count(*)最快。

  count(1)跟count(主键)一样,只扫描主键。count(*)跟count(非主键)一样,扫描整个表。明显前者更快一些。

## 18. 索引失效的场景有哪些？索引何时会失效？

https://mp.weixin.qq.com/s/bfCDkNKKayXBiNX5vuD4nw

## 19. 模糊匹配like %%的优化

- ICP

- 全文索引

  - MySQL 5.6开始支持全文索引，可以在变长的字符串类型上创建全文索引，来加速模糊匹配业务场景的DML操作。它是一个inverted index（反向索引），创建 `fulltext index` 时会自动创建6个 `auxiliary index tables`（辅助索引表），同时支持索引并行创建，并行度可以通过参数 `innodb_ft_sort_pll_degree` 设置，对于大表可以适当增加该参数值。
  - 删除全文索引的表的数据时，会导致辅助索引表大量delete操作，InnoDB内部采用标记删除，将已删除的DOC_ID都记录特殊的FTS_*_DELETED表中，但索引的大小不会减少，需要通过设置参数`innodb_optimize_fulltext_only=ON` 后，然后运行OPTIMIZE TABLE来重建全文索引。
  - IN NATURAL LANGUAGE MODE：默认模式，以自然语言的方式搜索，AGAINST('看风' IN NATURAL LANGUAGE MODE ) 等价于`AGAINST('看风')`。
  - IN BOOLEAN MODE：布尔模式，表是字符串前后的字符有特殊含义，如查找包含SK，但不包含Lyn的记录，可以用+，-符号。

- 生成列

  - MySQL 5.7开始支持生成列，生成列是由表达式的值计算而来，有两种模式：VIRTUAL和STORED，如果不指定默认是VIRTUAL，创建语法如下：

  ```sql
  col_name data_type [GENERATED ALWAYS] AS (expr)  [**VIRTUAL** | **STORED**] [NOT NULL | NULL]
  ```

  - **VIRTUAL**生成列用于复杂的条件定义，能够简化和统一查询，不占用空间，访问列是会做计算。

  - **STORED**生成列用作物化缓存，对于复杂的条件，可以降低计算成本，占用磁盘空间。

  - 支持辅助索引的创建，分区以及生成列可以模拟函数索引。

  - 不支持存储过程，用户自定义函数的表达式，`NONDETERMINISTIC`的内置函数，如NOW()， RAND()以及不支持子查询

  - 对于where条件后的 `like '%xxx'` 是无法利用索引扫描，可以利用MySQL 5.7的生成列模拟函数索引的方式解决，具体步骤如下：

    1. **利用内置reverse函数将like '%风云'反转为like '云风%'，基于此函数添加虚拟生成列。**
    2. **在虚拟生成列上创建索引。**
    3. **将SQL改写成通过生成列like reverse('%风云')去过滤，走生成列上的索引。**

    添加虚拟生成列并创建索引。

## 20. MySQL建索引需要遵循哪些原则呢

1.选择唯一性索引
唯一性索引的值是唯一的，可以更快速的通过该索引来确定某条记录。例如，学生表中学号是具有唯一性的字段。为该字段建立唯一性索引可以很快的确定某个学生的信息。如果使用姓名的话，可能存在同名现象，从而降低查询速度。

2.为经常需要排序、分组和联合操作的字段建立索引
经常需要ORDER BY、GROUP BY、DISTINCT和UNION等操作的字段，排序操作会浪费很多时间。如果为其建立索引，可以有效地避免排序操作。

3.为常作为查询条件的字段建立索引
如果某个字段经常用来做查询条件，那么该字段的查询速度会影响整个表的查询速度。因此，为这样的字段建立索引，可以提高整个表的查询速度。

4.限制索引的数目
索引的数目不是越多越好。每个索引都需要占用磁盘空间，索引越多，需要的磁盘空间就越大。修改表时，对索引的重构和更新很麻烦。越多的索引，会使更新表变得很浪费时间。

5.尽量使用数据量少的索引
如果索引的值很长，那么查询的速度会受到影响。例如，对一个CHAR(100)类型的字段进行全文检索需要的时间肯定要比对CHAR(10)类型的字段需要的时间要多。

6.尽量使用前缀来索引
如果索引字段的值很长，最好使用值的前缀来索引。例如，TEXT和BLOG类型的字段，进行全文检索会很浪费时间。如果只检索字段的前面的若干个字符，这样可以提高检索速度。

7.删除不再使用或者很少使用的索引
表中的数据被大量更新，或者数据的使用方式被改变后，原有的一些索引可能不再需要。数据库管理员应当定期找出这些索引，将它们删除，从而减少索引对更新操作的影响。

8.最左前缀匹配原则，非常重要的原则。
mysql会一直向右匹配直到遇到范围查询(>、<、between、like)就停止匹配，比如a 1=”” and=”” b=”2” c=”“> 3 and d = 4 如果建立(a,b,c,d)顺序的索引，d是用不到索引的，如果建立(a,b,d,c)的索引则都可以用到，a,b,d的顺序可以任意调整。

9.=和in可以乱序。
比如a = 1 and b = 2 and c = 3 建立(a,b,c)索引可以任意顺序，mysql的查询优化器会帮你优化成索引可以识别的形式

10.尽量选择区分度高的列作为索引。
区分度的公式是count(distinct col)/count(*)，表示字段不重复的比例，比例越大我们扫描的记录数越少，唯一键的区分度是1，而一些状态、性别字段可能在大数据面前区分度就 是0，那可能有人会问，这个比例有什么经验值吗？使用场景不同，这个值也很难确定，一般需要join的字段我们都要求是0.1以上，即平均1条扫描10条 记录

11.索引列不能参与计算，保持列“干净”。
比如from_unixtime(create_time) = ’2014-05-29’就不能使用到索引，原因很简单，b+树中存的都是数据表中的字段值，但进行检索时，需要把所有元素都应用函数才能比较，显然成本 太大。所以语句应该写成create_time = unix_timestamp(’2014-05-29’);

12.尽量的扩展索引，不要新建索引。
比如表中已经有a的索引，现在要加(a,b)的索引，那么只需要修改原来的索引即可

## 21. SQL注入

- SQL注入就是通过把SQL命令插入到Web表单递交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。
- 防止SQL注入，我们需要注意以下几个要点：
  - 1.永远不要信任用户的输入。对用户的输入进行校验，可以通过正则表达式，或限制长度；对单引号和 双"-"进行转换等。
  - 2.永远不要使用动态拼装sql，可以使用参数化的sql或者直接使用存储过程进行数据查询存取。
  - 3.永远不要使用管理员权限的数据库连接，为每个应用使用单独的权限有限的数据库连接。
  - 4.不要把机密信息直接存放，加密或者hash掉密码和敏感的信息。
  - 5.应用的异常信息应该给出尽可能少的提示，最好使用自定义的错误信息对原始错误信息进行包装
  - 6.sql注入的检测方法一般采取辅助软件或网站平台来检测，软件一般采用sql注入检测工具jsky，网站平台就有亿思网站安全平台检测工具。MDCSOFT SCAN等。采用MDCSOFT-IPS可以有效的防御SQL注入，XSS攻击等。

## 22. Mysql 主键设计

### 22.1 UUID

- UUID:通用唯一识别码（英语：Universally Unique Identifier，缩写：UUID）是用于计算机体系中以识别信息数目的一个128位标识符。
- UUID具有唯一性，这与其他大多数编号方案不同。重复UUID码概率接近零，可以忽略不计。UUID是由一组32位数的16进制数字所构成,标准型式包含32个16进制数字，以连字号分为五段，形式为8-4-4-4-12的32个字符。示例： 550e8400-e29b-41d4-a716-446655440000 
- 优点
  - 能够保证独立性，程序可以在不同的数据库间迁移，效果不受影响。
  - 保证生成的ID不仅是表独立的，而且是库独立的，这点在你想切分数据库的时候尤为重要。
- 缺点
  - 不易于存储：UUID太长，16字节128位，通常以36长度的字符串表示，很多场景不适用。
  - 信息不安全：基于MAC地址生成UUID的算法可能会造成MAC地址泄露，这个漏洞曾被用于寻找梅丽莎病毒的制作者位置。
  - ID作为主键时在特定的环境会存在一些问题，比如需要排序的时候——UUID是无序的。
  - MySQL官方有明确的建议主键要尽量越短越好，36个字符长度的UUID不符合要求。
  - 对MySQL索引不利：作为数据库主键，在InnoDB引擎下，UUID的无序性可能会引起数据位置频繁变动，严重影响性能。
- **结论**
  - uuid做主键适用于小规模分布式架构用。
  - 在使用uuid作为主键的时候，最好设计createtime（创建时间）列和updatetime（修改时间）列以应付可能的排序等场景。

### 22.2 自增主键

- 使用数据库的自动增长（auto_increment），是比较简单和常见的ID生成方案，数据库内部可以确保生成id的唯一性。
- **优点：**
  - 数据库自动编号，速度快，而且是增量增长，聚集型主键按顺序存放，对于检索非常有利。
  - 数字型，占用空间小，易排序，在程序中传递方便。
  - 能够保证独立性，程序可以在不同的数据库间迁移，效果不受影响。
  - 保证生成的ID不仅是表独立的，而且是库独立的，这点在你想切分数据库的时候尤为重要。
- **缺点：**
  - 因为自动增长，在手动要插入指定ID的记录时会显得麻烦，尤其是当系统与其它系统集成时，需要数据导入时，很难保证原系统的ID不发生主键冲突（前提是老系统也是数字型的）。特别是在新系统上线时，新旧系统并行存在，并且是异库异构的数据库的情况下，需要双向同步时，自增主键将是你的噩梦； 
  - 在系统集成或割接时，如果新旧系统主键不同是数字型就会导致修改主键数据类型，这也会导致其它有外键关联的表的修改，后果同样很严重； 
  - 若系统也是数字型的，在导入时，为了区分新老数据，可能想在老数据主键前统一加一个字符标识（例如“o”，old）来表示这是老数据，那么自动增长的数字型又面临一个挑战。
  - 如果经常有合并表的操作，就可能会出现主键重复的情况
  - 很难处理分布式存储的数据表。数据量特别大时，会导致查询数据库操作变慢。此时需要进行数据库的水平拆分，划分到不同的数据库中，那么当添加数据时，每个表都会自增长，导致主键冲突。

### 22.3 snowflake 算法

- snowflake 算法是 twitter 开源的分布式 id 生成算法，采用 Scala 语言实现，是把一个 64 位的 long 型的 id，1 个 bit 是不用的，用其中的 41 bit 作为毫秒数，用 10 bit 作为工作机器 id，12 bit 作为序列号。
  - 1 bit：不用，为啥呢？因为二进制里第一个 bit 为如果是 1，那么都是负数，但是我们生成的 id 都是正数，所以第一个 bit 统一都是 0。
  - 41 bit：表示的是时间戳，单位是毫秒。41 bit 可以表示的数字多达 `2^41 - 1`，也就是可以标识 `2^41 - 1` 个毫秒值，换算成年就是表示69年的时间。
  - 10 bit：记录工作机器 id，代表的是这个服务最多可以部署在 2^10台机器上哪，也就是1024台机器。但是 10 bit 里 5 个 bit 代表机房 id，5 个 bit 代表机器 id。意思就是最多代表 `2^5`个机房（32个机房），每个机房里可以代表 `2^5` 个机器（32台机器）。
  - 12 bit：这个是用来记录同一个毫秒内产生的不同 id，12 bit 可以代表的最大正整数是 `2^12 - 1 = 4096`，也就是说可以用这个 12 bit 代表的数字来区分**同一个毫秒内**的 4096 个不同的 id。