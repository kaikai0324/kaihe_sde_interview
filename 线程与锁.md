# 1.线程wait(),sleep():

wait()和sleep()的关键的区别在于，wait()是用于线程间通信的，而sleep()是用于短时间暂停当前线程。更加明显的一个区别在于，当一个线程调用wait()方法的时候，会释放它锁持有的对象的管程和锁，但是调用sleep()方法的时候，不会释放他所持有的管程。
1.所属的类不同：
sleep方法是定义在Thread上
wait方法是定义在Object上
2.对于锁资源的处理方式不同
sleep不会释放锁
wait会释放锁
3.使用范围：
sleep可以使用在任何代码块
wait必须在同步方法或同步代码块执行
4.唤醒：
void notify()可以唤醒等待（wait）的单个线程，而sleep不能被唤醒

线程sleep()，yield():
1. 都会暂缓执行当前线程；
2. 如果已经持有锁，那么在等待过程中都不会释放锁；

不同点在于：
1. Thread.sleep()可以精确指定休眠的时间，而Thread.yield()依赖于CPU的时间片划分，在我的电脑上大约为20微秒；
2. Thread.sleep()会抛出中断异常，且能被中断，而Thread.yield()不可以；
yield()理解为线程让步
yeild()只是让当前线程暂停一下，让系统的线程调度器重新调度一次，完全可能的情况是：当某个线程调用了yield()线程暂停之后，线程调度器又将其调度出来重新执行。当某个线程调用了yield()方法暂停之后，只有优先级与当前线程相同，或者优先级比当前线程更高的处于就绪状态的线程才会获得执行机会。



# 2.线程生命周期

1.当线程调用wait()或者join()时，线程都会进入到waiting（等待）状态，当调用notify或notifyAll时，或者join的线程执行结束后，会进入runnable状态
2.当线程调用sleep(time)，或者wait(time)时，进入timed waiting状态
join：可理解为插队，对当前线程是一种特殊的wait。当前运行线程调用另一个线程的join方法，当前线程进入阻塞状态直到被调用线程运行结束，之后当前线程继续。 注意该方法也需要捕捉异常。等待调用join方法的线程结束，再继续执行。如在main()中调用thread.join()，意为阻塞main线程并调用thread线程，thread线程运行结束之后main线程继续


Thread.interrupt()方法不会中断一个正在运行的线程。它的作用是，在线程受到阻塞时抛出一个中断信号，这样线程就得以退出阻塞的状态。更确切的说，如果线程被Object.wait,Thread.join和Thread.sleep三种方法之一阻塞，那么，它将接收到一个中断异常（InterruptedException），从而提早地终结被阻塞状态。

interrupt方法并不是强制终止线程，它只能设置线程的interrupted状态（调用后设置为true），而在线程中一般使用一下方式：
while (!Thread.currentThread().isInterrupted() && more work to do)，来结束run方法



# 3.线程池

## 3.1新建线程池：

1.Excutors.newFixedThreadPool(int)
创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。newFixedThreadPool固定线程池，  使用完毕必须手动关闭线程池，否则会一直在内存中存在。

2.Excutors.newSingleThreadExecutor()
创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序执行。newSingleThreadExecutor创建的线程池corePoolSize和maximumPoolSize值都设置为1，它使用的LinkedBlockingQueue。

3.Excutors.newCachedThreadPool()
创建一个可缓存线程池，如果线程池长度超出处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
newCachedThreadPool将corePoolSize设置为0，将maximumPoolSize设置为Integer.MAX_VALUE，使用的SynchronousQueue，多余的空闲线程的存活时间60秒。

4.Excutors.newScheduledThreadPool(int)
创建一个周期性的线程池，支持定时及周期性执行任务。



## 3.2线程池7大参数：

1.corePoolSize(int)：核心线程数量。默认情况下，在创建了线程池后，线程池中的线程数为0，当有任务来之后，就会创建一个线程去执行任务，当线程池中的线程数目达到corePoolSize后，就会把到达的任务放到任务队列当中。线程池将长期保证这些线程处于存活状态，即使线程已经处于闲置状态。除非配置了allowCoreThreadTimeOut=true，核心线程数的线程也将不再保证长期存活于线程池内，在空闲时间超过keepAliveTime后被销毁。

2.workQueue：阻塞队列，存放等待执行的任务，线程从workQueue中取任务，若无任务将阻塞等待。当线程池中线程数量达到corePoolSize后，就会把新任务放到该队列当中。JDK提供了四个可直接使用的队列实现，分别是：基于数组的有界队列ArrayBlockingQueue、基于链表的无界队列LinkedBlockingQueue、只有一个元素的同步队列SynchronousQueue、优先级队列PriorityBlockingQueue。在实际使用时一定要设置队列长度。

3.maximumPoolSize(int)：线程池内的最大线程数量，线程池内维护的线程不得超过该数量，大于核心线程数量小于最大线程数量的线程将在空闲时间超过keepAliveTime后被销毁。当阻塞队列存满后，将会创建新线程执行任务，线程的数量不会大于maximumPoolSize。

4.keepAliveTime(long)：线程存活时间，若线程数超过了corePoolSize，线程闲置时间超过了存活时间，该线程将被销毁。除非配置了allowCoreThreadTimeOut=true，核心线程数的线程也将不再保证长期存活于线程池内，在空闲时间超过keepAliveTime后被销毁。

5.unit：keepAliveTime的单位

6.threadFactory：创建线程的工厂，虽说JDK提供了线程工厂的默认实现DefaultThreadFactory，但还是建议自定义实现最好，这样可以自定义线程创建的过程，例如线程分组、自定义线程名称等。

7.handler：拒绝策略

当工作队列中的任务已到达最大限制，并且线程池中的线程数量也达到最大限制（maximumPoolSize），这时如果有新任务提交进来，如何来拒绝请求执行的runnable的策略
①CallerRunsPolicy
该策略下，使用调用者所在线程来运行任务。在调用者线程中直接执行被拒绝任务的run方法，除非线程池已shutdown，则直接抛弃任务。
②AbortPolicy
该策略下，直接丢弃任务，并抛出RejectedExecutionException异常。
③DiscardPolicy
该策略下，直接丢弃任务，什么都不做。
④DiscardOldestPolicy
该策略下，抛弃进入队列最早的那个任务，然后尝试把这次拒绝的任务放入队列









# 4.threadlocal:

threadlocal里存储ThreadLoalMap。ThreadLocalMap是threadlocal里的静态内部类
ThreadLocal的实现是这样的：每个Thread 维护一个 ThreadLocalMap 映射表，这个映射表的 key是 ThreadLocal 实例本身，value是真正需要存储的 Object（同线程每次new一个ThreadLocal，map桶被占用+1）。
也就是说 ThreadLocal 本身并不存储值，它只是作为一个 key 来让线程从 ThreadLocalMap 获取 value。值得注意的是图中的虚线，表示 ThreadLocalMap 是使用 ThreadLocal 的弱引用作为 Key的，弱引用的对象在 GC 时会被回收。



ThreadLocal为什么会内存泄漏：
ThreadLocalMap的key为ThreadLocal对象的弱引用，我们知道弱引用有利于GC的回收，当key == null时，GC就会回收这部分空间，但value不一定能被回收，因为他和Current Thread之间还存在一个强引用的关系。
由于这个强引用的关系，会导致value无法回收，如果线程对象不消除这个强引用的关系，就可能会出现OOM。有些时候我们调用ThreadLocalMap的remove()方法进行显式处理。

在ThreadLoalMap中，也是初始化一个大小16的Entry数组，Entry对象用来保存每一个key-value键值对，只不过这里的key永远都是ThreadLocal对象，通过ThreadLocal对象的set方法，结果把ThreadLocal对象自己当做key，放进了ThreadLoalMap中。当执行get方法中，是从当前线程的threadLocals变量获取.
ThreadLoalMap的Entry是继承WeakReference，和HashMap很大的区别是，Entry中没有next字段，所以就不存在链表的情况了。

HashMap:底层为Node实现了Entry接口
static class Node<K,V> implements Map.Entry<K,V> {
        final int hash;
        final K key;
        V value;
        Node<K,V> next;

        Node(int hash, K key, V value, Node<K,V> next) {
            this.hash = hash;
            this.key = key;
            this.value = value;
            this.next = next;
        }......





# 5.volatile关键字：

不保证原子性，保证可见性与有序性
保证线程间变量的可见性。
禁止CPU进行指令重排序。

volatile实际也是JVM通过加内存屏障实现禁止指令重排

JVM指令重排：
在虚拟机层面，为了尽可能减少内存操作速度远慢于CPU运行速度所带来的CPU空置的影响，虚拟机会按照自己的一些规则(这规则后面再叙述)将程序编写顺序打乱——即写在后面的代码在时间顺序上可能会先执行，而写在前面的代码会后执行——以尽可能充分地利用CPU。拿上面的例子来说：假如不是a=1的操作，而是a=new byte1024*1024，那么它会运行地很慢，此时CPU是等待其执行结束呢，还是先执行下面那句flag=true呢？显然，先执行flag=true可以提前使用CPU，加快整体效率，当然这样的前提是不会产生错误(什么样的错误后面再说)。虽然这里有两种情况：后面的代码先于前面的代码开始执行；前面的代码先开始执行，但当效率较慢的时候，后面的代码开始执行并先于前面的代码执行结束。不管谁先开始，总之后面的代码在一些情况下存在先结束的可能。


禁止指令重排：
被volatile修饰的变量，会加一个lock前缀的汇编指令（lock cmpxchg）。若变量被修改后，会立刻将变量由工作内存回写到主存中。那么意味了之前的操作已经执行完毕。这就是内存屏障。它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成。非常经典的例子是在单例方法中同时对字段加入voliate，就是为了防止指令重排序。

# 6.Lock接口的实现类：Reentrantlock

private final Reentrantlock lockname = new Reentrantlock();
1.Reentrantlock为显示定义的加锁
try{
   lockname.lock();
   ...
   ...
}
finally {
   lockname.unlock();
}

2.ReentrantLock与公平锁、非公平锁实现
//创建一个非公平锁，默认是非公平锁
Lock lock = new ReentrantLock();
Lock lock = new ReentrantLock(false);

//创建一个公平锁，构造传参true
Lock lock = new ReentrantLock(true);

所谓的公平与非公平指的是在请求先后顺序上，先对锁进行请求的就一定先获取到锁，那么这就是公平锁，反之，如果对于锁的获取并没有时间上的先后顺序，如后请求的线程可能先获取到锁，这就是非公平锁，一般而言非，非公平锁机制的效率往往会胜过公平锁的机制，但在某些场景下，可能更注重时间先后顺序，那么公平锁自然是很好的选择。





# 7.synchronized

synchronized可重入锁的实现原理：
synchronized底层的实现原理是利用计算机系统的mutex Lock实现。每一个可重入锁都会关联一个线程ID和一个锁状态status。
当一个线程请求方法时，会去检查锁状态，如果锁状态是0，代表该锁没有被占用，直接进行CAS操作获取锁，将线程ID替换成自己的线程ID。如果锁状态不是0，代表有线程在访问该方法。此时，如果线程ID是自己的线程ID，如果是可重入锁，会将status自增1，然后获取到该锁，进而执行相应的方法。如果是非重入锁，就会进入阻塞队列等待。
释放锁时，可重入锁，每一次退出方法，就会将status减1，直至status的值为0，最后释放该锁。
释放锁时，非可重入锁，线程退出方法，直接就会释放该锁。





Synchronized应用举例：生产者消费者模型。利用缓冲区——管程法

消费者线程需要等待直到生产者线程完成一次写入操作。生产者线程需要等待消费者线程完成一次读取操作。假设没有应用Synchronized关键字，当消费者线程执行wait操作的同时，生产线线程执行notify，生产者线程可能在等待队列中找不到消费者线程。导致消费者线程一直处于阻塞状态。那么这个模型就要失败了。所以必须要加Synchronized关键字。


wait(),notify(),notifyAll()必须要在Synchronized关键中使用。否则抛出IllegalMonitorStateException







# 8.死锁：

一、产生死锁的四个必要条件：
1.互斥条件
一个资源每次只能被一个进程使用，即在一段时间内某资源仅为一个进程所使用。此时如果有其他进程请求该资源，则请求进程只能等待。
2.请求与保持条件
进程中已经保持了至少一个资源，但又提出了新的资源请求，而该资源已经被其他进程占有，此时请求进程被阻塞，但对自己已经获得资源保持不放。
3.不可剥夺条件
进程未使用完的资源在未使用完毕之前，不能被其他进程强行夺走，即只能由获得该资源的进程自己来释放。
4.循环等待条件
若干进程间形成首尾相接循环等待资源的关系。在发生死锁时必然存在一个进程等待队列{P1，P2，…,Pn},其中P1等待P2占有的资源，P2等待P3占有的资源，…，Pn等待P1占有的资源，形成一个进程等待环路，环路中每一个进程所占有的资源同时被另一个申请。

注意：这四个条件是死锁的必然条件，只要系统发生死锁，这些条件必然成立。只要有上述条件有一条不满足，就不会发生死锁。


死锁的预防：死锁的预防是设法至少破坏产生死锁的四个必要条件之一
我们可以通过破坏产生死锁的四个必要条件来预防死锁，由于资源互斥是固有特性无法改变的。
1.破坏“请求与保持”条件
方法一：静态分配，每个进程在开始执行时就申请他所需要的全部资源。
方法二：动态分配，每个进程在申请所需要的资源时他本身不占用系统资源。
2.破坏“不可剥夺”条件
一个进程不可获得其所需要的全部资源便处于等待状态，等待期间他占用的资源将被隐式的释放重新加入到系统的资源列表中，可以被其他进程使用，而等待的进程只有重新获得自己原有的资源以及新申请的资源才可以重新启动，执行。
3.破坏“循环等待”条件
采用资源有序分配的基本思想。将系统中的资源顺序进行编号，将紧缺的、稀少的资源采用较大的编号，申请资源时必须按照编号的顺序执行，一个进程只有较小编号的进程才能申请较大编号的进程。


死锁的避免：银行家算法

银行家算法的基本思想是：分配资源之前，判断系统是否安全，如果安全才会进行资源分配。
每一个线程进入系统时，它必须声明在运行过程中，所需的每种资源类型最大数目，其数目不应超过系统所拥有每种资源总量，当线程请求一组资源系统必须确定有足够资源分配给该进程，若有在进一步计算这些资源分配给进程后，是否会使系统处于不安全状态，不会（即若能在分配资源时找到一个安全序列），则将资源分配给它，否则等待。

即：系统资源大于请求，则安全